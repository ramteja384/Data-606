{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uAXnyQehyi0W",
   "metadata": {
    "id": "uAXnyQehyi0W"
   },
   "source": [
    "#**NETWORK INTRUSION DETECTION SYSTEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "GgFpbD8LOEKE",
   "metadata": {
    "id": "GgFpbD8LOEKE"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 10000)  # Width of the display in characters\n",
    "pd.set_option('display.max_rows', 100)  # Maximum number of rows to display\n",
    "pd.set_option('display.max_columns', 100)  # Maximum number of columns to display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics # Importing 'metrics' from sklearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_XSLY8cpys7P",
   "metadata": {
    "id": "_XSLY8cpys7P"
   },
   "source": [
    "\n",
    "\n",
    "*   The code mounts Google Drive to access files and directories from within Google Colab.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "JJJv9vGJOS-z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJJv9vGJOS-z",
    "outputId": "f5677709-9c9d-47ae-9e68-0c31bf3c7731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4GpT00GbOEKH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "4GpT00GbOEKH",
    "outputId": "41045f68-a8b7-4581-fb34-5832fc8329a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b334719f-b278-4ec4-8156-48f7be36b193\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>ackdat</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121478</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>252</td>\n",
       "      <td>254</td>\n",
       "      <td>14158.942380</td>\n",
       "      <td>8495.365234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.295600</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>30.177547</td>\n",
       "      <td>11.830604</td>\n",
       "      <td>255</td>\n",
       "      <td>621772692</td>\n",
       "      <td>2202533631</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.649902</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>8395.112305</td>\n",
       "      <td>503571.312500</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>49.915000</td>\n",
       "      <td>15.432865</td>\n",
       "      <td>61.426934</td>\n",
       "      <td>1387.778330</td>\n",
       "      <td>255</td>\n",
       "      <td>1417884146</td>\n",
       "      <td>3077387971</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.623129</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>1572.271851</td>\n",
       "      <td>60929.230470</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>231.875571</td>\n",
       "      <td>102.737203</td>\n",
       "      <td>17179.586860</td>\n",
       "      <td>11420.926230</td>\n",
       "      <td>255</td>\n",
       "      <td>2116150707</td>\n",
       "      <td>2963114973</td>\n",
       "      <td>255</td>\n",
       "      <td>0.111897</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.050439</td>\n",
       "      <td>46</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.681642</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>2740.178955</td>\n",
       "      <td>3358.622070</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>152.876547</td>\n",
       "      <td>90.235726</td>\n",
       "      <td>259.080172</td>\n",
       "      <td>4991.784669</td>\n",
       "      <td>255</td>\n",
       "      <td>1107119177</td>\n",
       "      <td>1047442890</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>254</td>\n",
       "      <td>252</td>\n",
       "      <td>8561.499023</td>\n",
       "      <td>3987.059814</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47.750333</td>\n",
       "      <td>75.659602</td>\n",
       "      <td>2415.837634</td>\n",
       "      <td>115.807000</td>\n",
       "      <td>255</td>\n",
       "      <td>2436137549</td>\n",
       "      <td>1977154190</td>\n",
       "      <td>255</td>\n",
       "      <td>0.128381</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.057234</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b334719f-b278-4ec4-8156-48f7be36b193')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b334719f-b278-4ec4-8156-48f7be36b193 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b334719f-b278-4ec4-8156-48f7be36b193');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-599e56bb-5170-4ccc-9b83-e2e170421bab\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-599e56bb-5170-4ccc-9b83-e2e170421bab')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-599e56bb-5170-4ccc-9b83-e2e170421bab button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  sttl  dttl         sload          dload  sloss  dloss      sinpkt      dinpkt          sjit          djit  swin       stcpb       dtcpb  dwin    tcprtt    synack    ackdat  smean  dmean  trans_depth  response_body_len  ct_srv_src  ct_state_ttl  ct_dst_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports attack_cat  label\n",
       "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   252   254  14158.942380    8495.365234      0      0   24.295600    8.375000     30.177547     11.830604   255   621772692  2202533631   255  0.000000  0.000000  0.000000     43     43            0                  0           1             0           1                 1                 1               1             0           0                 0           1           1                0     Normal      0\n",
       "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372    62   252   8395.112305  503571.312500      2     17   49.915000   15.432865     61.426934   1387.778330   255  1417884146  3077387971   255  0.000000  0.000000  0.000000     52   1106            0                  0          43             1           1                 1                 1               2             0           0                 0           1           6                0     Normal      0\n",
       "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161    62   252   1572.271851   60929.230470      1      6  231.875571  102.737203  17179.586860  11420.926230   255  2116150707  2963114973   255  0.111897  0.061458  0.050439     46    824            0                  0           7             1           2                 1                 1               3             0           0                 0           2           6                0     Normal      0\n",
       "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108    62   252   2740.178955    3358.622070      1      3  152.876547   90.235726    259.080172   4991.784669   255  1107119177  1047442890   255  0.000000  0.000000  0.000000     52     64            0                  0           1             1           2                 1                 1               3             1           1                 0           2           1                0     Normal      0\n",
       "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   254   252   8561.499023    3987.059814      2      1   47.750333   75.659602   2415.837634    115.807000   255  2436137549  1977154190   255  0.128381  0.071147  0.057234     53     45            0                  0          43             1           2                 2                 1              40             0           0                 0           2          39                0     Normal      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reads a CSV file containing training data from Google Drive\n",
    "train = pd.read_csv('/content/drive/MyDrive/UNSW_NB15_training-set.csv')\n",
    "#Displays the first few rows of the DataFrame.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "l_hXr-uH7XHn",
   "metadata": {
    "id": "l_hXr-uH7XHn"
   },
   "outputs": [],
   "source": [
    "# Replacing '-' with NaN in column 'Service'\n",
    "train['service'] = train['service'].replace('-', pd.NA)\n",
    "\n",
    "# Calculating the mode value of column 'Service' (ignoring NaN values)\n",
    "mode_value = train['service'].mode(dropna=True)[0]\n",
    "\n",
    "# Replacing NaN with the mode value in column 'Service'\n",
    "train['service'] = train['service'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "NyBqK0RCOEKI",
   "metadata": {
    "id": "NyBqK0RCOEKI"
   },
   "outputs": [],
   "source": [
    "# Drops the 'id' and 'label' columns from the DataFrame 'train'\n",
    "train.drop(columns=[\"id\",\"label\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aoC034s7vFG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "4aoC034s7vFG",
    "outputId": "e1845750-2272-4d7f-d4e8-9b5735df6f1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a6cdfa71-08ec-47e8-b901-7ff236df0300\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>ackdat</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121478</td>\n",
       "      <td>tcp</td>\n",
       "      <td>dns</td>\n",
       "      <td>FIN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>252</td>\n",
       "      <td>254</td>\n",
       "      <td>14158.942380</td>\n",
       "      <td>8495.365234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.295600</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>30.177547</td>\n",
       "      <td>11.830604</td>\n",
       "      <td>255</td>\n",
       "      <td>621772692</td>\n",
       "      <td>2202533631</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649902</td>\n",
       "      <td>tcp</td>\n",
       "      <td>dns</td>\n",
       "      <td>FIN</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>8395.112305</td>\n",
       "      <td>503571.312500</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>49.915000</td>\n",
       "      <td>15.432865</td>\n",
       "      <td>61.426934</td>\n",
       "      <td>1387.778330</td>\n",
       "      <td>255</td>\n",
       "      <td>1417884146</td>\n",
       "      <td>3077387971</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.623129</td>\n",
       "      <td>tcp</td>\n",
       "      <td>dns</td>\n",
       "      <td>FIN</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>1572.271851</td>\n",
       "      <td>60929.230470</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>231.875571</td>\n",
       "      <td>102.737203</td>\n",
       "      <td>17179.586860</td>\n",
       "      <td>11420.926230</td>\n",
       "      <td>255</td>\n",
       "      <td>2116150707</td>\n",
       "      <td>2963114973</td>\n",
       "      <td>255</td>\n",
       "      <td>0.111897</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.050439</td>\n",
       "      <td>46</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.681642</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>2740.178955</td>\n",
       "      <td>3358.622070</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>152.876547</td>\n",
       "      <td>90.235726</td>\n",
       "      <td>259.080172</td>\n",
       "      <td>4991.784669</td>\n",
       "      <td>255</td>\n",
       "      <td>1107119177</td>\n",
       "      <td>1047442890</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449454</td>\n",
       "      <td>tcp</td>\n",
       "      <td>dns</td>\n",
       "      <td>FIN</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>254</td>\n",
       "      <td>252</td>\n",
       "      <td>8561.499023</td>\n",
       "      <td>3987.059814</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47.750333</td>\n",
       "      <td>75.659602</td>\n",
       "      <td>2415.837634</td>\n",
       "      <td>115.807000</td>\n",
       "      <td>255</td>\n",
       "      <td>2436137549</td>\n",
       "      <td>1977154190</td>\n",
       "      <td>255</td>\n",
       "      <td>0.128381</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.057234</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6cdfa71-08ec-47e8-b901-7ff236df0300')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a6cdfa71-08ec-47e8-b901-7ff236df0300 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a6cdfa71-08ec-47e8-b901-7ff236df0300');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7fab8aec-d375-4a70-ac10-0b769df854f3\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fab8aec-d375-4a70-ac10-0b769df854f3')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7fab8aec-d375-4a70-ac10-0b769df854f3 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        dur proto service state  spkts  dpkts  sbytes  dbytes       rate  sttl  dttl         sload          dload  sloss  dloss      sinpkt      dinpkt          sjit          djit  swin       stcpb       dtcpb  dwin    tcprtt    synack    ackdat  smean  dmean  trans_depth  response_body_len  ct_srv_src  ct_state_ttl  ct_dst_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports attack_cat\n",
       "0  0.121478   tcp     dns   FIN      6      4     258     172  74.087490   252   254  14158.942380    8495.365234      0      0   24.295600    8.375000     30.177547     11.830604   255   621772692  2202533631   255  0.000000  0.000000  0.000000     43     43            0                  0           1             0           1                 1                 1               1             0           0                 0           1           1                0     Normal\n",
       "1  0.649902   tcp     dns   FIN     14     38     734   42014  78.473372    62   252   8395.112305  503571.312500      2     17   49.915000   15.432865     61.426934   1387.778330   255  1417884146  3077387971   255  0.000000  0.000000  0.000000     52   1106            0                  0          43             1           1                 1                 1               2             0           0                 0           1           6                0     Normal\n",
       "2  1.623129   tcp     dns   FIN      8     16     364   13186  14.170161    62   252   1572.271851   60929.230470      1      6  231.875571  102.737203  17179.586860  11420.926230   255  2116150707  2963114973   255  0.111897  0.061458  0.050439     46    824            0                  0           7             1           2                 1                 1               3             0           0                 0           2           6                0     Normal\n",
       "3  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108    62   252   2740.178955    3358.622070      1      3  152.876547   90.235726    259.080172   4991.784669   255  1107119177  1047442890   255  0.000000  0.000000  0.000000     52     64            0                  0           1             1           2                 1                 1               3             1           1                 0           2           1                0     Normal\n",
       "4  0.449454   tcp     dns   FIN     10      6     534     268  33.373826   254   252   8561.499023    3987.059814      2      1   47.750333   75.659602   2415.837634    115.807000   255  2436137549  1977154190   255  0.128381  0.071147  0.057234     53     45            0                  0          43             1           2                 2                 1              40             0           0                 0           2          39                0     Normal"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first 5 rows after replacing nans with mode value in service column\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "RqqAeBuUOEKI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "RqqAeBuUOEKI",
    "outputId": "309ce0cc-41d0-4a00-ee67-b9107f875fd8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "test"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-9067678c-15e8-426a-9147-9a2ca1c64e4f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>ackdat</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>180363632.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>881000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>854400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>600000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>850400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9067678c-15e8-426a-9147-9a2ca1c64e4f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-9067678c-15e8-426a-9147-9a2ca1c64e4f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-9067678c-15e8-426a-9147-9a2ca1c64e4f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-3f827c95-0af5-4d6b-b704-660b0f8c72d2\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f827c95-0af5-4d6b-b704-660b0f8c72d2')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-3f827c95-0af5-4d6b-b704-660b0f8c72d2 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes         rate  sttl  dttl        sload  dload  sloss  dloss  sinpkt  dinpkt  sjit  djit  swin  stcpb  dtcpb  dwin  tcprtt  synack  ackdat  smean  dmean  trans_depth  response_body_len  ct_srv_src  ct_state_ttl  ct_dst_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports attack_cat  label\n",
       "0   1  0.000011   udp       -   INT      2      0     496       0   90909.0902   254     0  180363632.0    0.0      0      0   0.011     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    248      0            0                  0           2             2           1                 1                 1               2             0           0                 0           1           2                0     Normal      0\n",
       "1   2  0.000008   udp       -   INT      2      0    1762       0  125000.0003   254     0  881000000.0    0.0      0      0   0.008     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    881      0            0                  0           2             2           1                 1                 1               2             0           0                 0           1           2                0     Normal      0\n",
       "2   3  0.000005   udp       -   INT      2      0    1068       0  200000.0051   254     0  854400000.0    0.0      0      0   0.005     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    534      0            0                  0           3             2           1                 1                 1               3             0           0                 0           1           3                0     Normal      0\n",
       "3   4  0.000006   udp       -   INT      2      0     900       0  166666.6608   254     0  600000000.0    0.0      0      0   0.006     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    450      0            0                  0           3             2           2                 2                 1               3             0           0                 0           2           3                0     Normal      0\n",
       "4   5  0.000010   udp       -   INT      2      0    2126       0  100000.0025   254     0  850400000.0    0.0      0      0   0.010     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0   1063      0            0                  0           3             2           2                 2                 1               3             0           0                 0           2           3                0     Normal      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reads a CSV file containing training data from Google Drive\n",
    "test = pd.read_csv('/content/drive/MyDrive/UNSW_NB15_testing-set.csv')\n",
    "# Displays the first few rows of the DataFrame\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "YUDvyG0473Cx",
   "metadata": {
    "id": "YUDvyG0473Cx"
   },
   "outputs": [],
   "source": [
    "# Replacing '-' with NaN in column 'Service'\n",
    "test['service'] = test['service'].replace('-', pd.NA)\n",
    "\n",
    "# Calculating the mode value of column 'Service' (ignoring NaN values)\n",
    "mode_value_test = test['service'].mode(dropna=True)[0]\n",
    "\n",
    "# Replacing NaN with the mode value in column 'Service'\n",
    "test['service'] = test['service'].fillna(mode_value_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "zY2rYhZsOEKJ",
   "metadata": {
    "id": "zY2rYhZsOEKJ"
   },
   "outputs": [],
   "source": [
    "# Drops the 'id' and 'label' columns from the DataFrame 'test'\n",
    "test.drop(columns=[\"id\",\"label\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "DWBFRWkq8AwO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "DWBFRWkq8AwO",
    "outputId": "1f942461-3980-47e4-b1ad-9d5f9ec9b1a0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "test"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-17ba50df-d057-4432-8380-67ee83c87809\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>ackdat</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>180363632.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>881000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>854400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>600000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>850400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17ba50df-d057-4432-8380-67ee83c87809')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-17ba50df-d057-4432-8380-67ee83c87809 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-17ba50df-d057-4432-8380-67ee83c87809');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ad89e7b2-665a-44da-bc72-0adafdaae42e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad89e7b2-665a-44da-bc72-0adafdaae42e')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ad89e7b2-665a-44da-bc72-0adafdaae42e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        dur proto service state  spkts  dpkts  sbytes  dbytes         rate  sttl  dttl        sload  dload  sloss  dloss  sinpkt  dinpkt  sjit  djit  swin  stcpb  dtcpb  dwin  tcprtt  synack  ackdat  smean  dmean  trans_depth  response_body_len  ct_srv_src  ct_state_ttl  ct_dst_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports attack_cat\n",
       "0  0.000011   udp     dns   INT      2      0     496       0   90909.0902   254     0  180363632.0    0.0      0      0   0.011     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    248      0            0                  0           2             2           1                 1                 1               2             0           0                 0           1           2                0     Normal\n",
       "1  0.000008   udp     dns   INT      2      0    1762       0  125000.0003   254     0  881000000.0    0.0      0      0   0.008     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    881      0            0                  0           2             2           1                 1                 1               2             0           0                 0           1           2                0     Normal\n",
       "2  0.000005   udp     dns   INT      2      0    1068       0  200000.0051   254     0  854400000.0    0.0      0      0   0.005     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    534      0            0                  0           3             2           1                 1                 1               3             0           0                 0           1           3                0     Normal\n",
       "3  0.000006   udp     dns   INT      2      0     900       0  166666.6608   254     0  600000000.0    0.0      0      0   0.006     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    450      0            0                  0           3             2           2                 2                 1               3             0           0                 0           2           3                0     Normal\n",
       "4  0.000010   udp     dns   INT      2      0    2126       0  100000.0025   254     0  850400000.0    0.0      0      0   0.010     0.0   0.0   0.0     0      0      0     0     0.0     0.0     0.0   1063      0            0                  0           3             2           2                 2                 1               3             0           0                 0           2           3                0     Normal"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first 5 rows after replacing nans with mode value in service column\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2lUZyZYxlk_4",
   "metadata": {
    "id": "2lUZyZYxlk_4"
   },
   "outputs": [],
   "source": [
    "l = ['Analysis','Backdoor','Shellcode','Worms']\n",
    "for i in l:\n",
    "    #data[data.name.isin(list2) == False]\n",
    "    train = train[train.attack_cat.isin(l) == False]\n",
    "    test = test[test.attack_cat.isin(l) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "AQM8hOTH8P7_",
   "metadata": {
    "id": "AQM8hOTH8P7_"
   },
   "outputs": [],
   "source": [
    "# Here attack_cat column is the target variable\n",
    "y_train = train['attack_cat']\n",
    "y_test  = test['attack_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9zwazgtrd_bP",
   "metadata": {
    "id": "9zwazgtrd_bP"
   },
   "outputs": [],
   "source": [
    "categorical_columns = train.select_dtypes(include=['object']).columns.tolist()\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode each categorical column\n",
    "for column in categorical_columns:\n",
    "    train[column] = le.fit_transform(train[column])\n",
    "    test[column] = le.fit_transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "w1o5EcRg9H56",
   "metadata": {
    "id": "w1o5EcRg9H56"
   },
   "outputs": [],
   "source": [
    "# Encoding the target labels using label encoder\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded  = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eKfVtyydz7vT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKfVtyydz7vT",
    "outputId": "936b8f59-2bbc-4f60-b3c8-609e600a0d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Mapping: {0: 'DoS', 1: 'Exploits', 2: 'Fuzzers', 3: 'Generic', 4: 'Normal', 5: 'Reconnaissance'}\n"
     ]
    }
   ],
   "source": [
    "# Check the mapping of numerical values to classes\n",
    "class_mapping = {index: label for index, label in enumerate(le.classes_)}\n",
    "print(\"Class Mapping:\", class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NLXDTTF9OEKP",
   "metadata": {
    "id": "NLXDTTF9OEKP"
   },
   "source": [
    "#### Dropping highly correlated features from the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vYWuULUdOEKQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYWuULUdOEKQ",
    "outputId": "d02cabed-6573-4a50-99b8-ec37c6d15edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed highly correlated features: {'sloss', 'ct_dst_sport_ltm', 'ct_ftp_cmd', 'ct_dst_src_ltm', 'ct_src_ltm', 'dwin', 'synack', 'dbytes', 'ackdat', 'sbytes', 'ct_src_dport_ltm', 'is_sm_ips_ports', 'ct_srv_dst', 'dloss'}\n"
     ]
    }
   ],
   "source": [
    "# Calculating the correlation matrix\n",
    "corr_matrix = train.corr(numeric_only=True).abs()\n",
    "\n",
    "# Creating a mask to identify highly correlated features\n",
    "upper_triangle_mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "\n",
    "# Identifying highly correlated features\n",
    "highly_correlated_features = (corr_matrix * upper_triangle_mask).stack()\n",
    "highly_correlated_features = highly_correlated_features[highly_correlated_features > 0.9]  # Setting correlation threshold here\n",
    "\n",
    "# Removing one feature from each highly correlated pair\n",
    "features_to_drop = set()\n",
    "for pair in highly_correlated_features.index:\n",
    "    features_to_drop.add(pair[1])  # Dropping the second feature in each pair\n",
    "\n",
    "# Dropping highly correlated features from the train dataset\n",
    "train_filtered = train.drop(columns=features_to_drop)\n",
    "\n",
    "# Dropping highly correlated features from the test dataset\n",
    "test_filtered = test.drop(columns=features_to_drop)\n",
    "\n",
    "# Printing the names of features removed\n",
    "print(\"Removed highly correlated features:\", features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "n7-MQq-qOEKR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "n7-MQq-qOEKR",
    "outputId": "d06becd6-baf8-41a0-c0c9-2c495102bac4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train_filtered"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3db7a911-4962-4757-bfee-a7e8cd4d7dc5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121478</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>252</td>\n",
       "      <td>254</td>\n",
       "      <td>14158.942380</td>\n",
       "      <td>8495.365234</td>\n",
       "      <td>24.295600</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>30.177547</td>\n",
       "      <td>11.830604</td>\n",
       "      <td>255</td>\n",
       "      <td>621772692</td>\n",
       "      <td>2202533631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649902</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>8395.112305</td>\n",
       "      <td>503571.312500</td>\n",
       "      <td>49.915000</td>\n",
       "      <td>15.432865</td>\n",
       "      <td>61.426934</td>\n",
       "      <td>1387.778330</td>\n",
       "      <td>255</td>\n",
       "      <td>1417884146</td>\n",
       "      <td>3077387971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.623129</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>1572.271851</td>\n",
       "      <td>60929.230470</td>\n",
       "      <td>231.875571</td>\n",
       "      <td>102.737203</td>\n",
       "      <td>17179.586860</td>\n",
       "      <td>11420.926230</td>\n",
       "      <td>255</td>\n",
       "      <td>2116150707</td>\n",
       "      <td>2963114973</td>\n",
       "      <td>0.111897</td>\n",
       "      <td>46</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.681642</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>2740.178955</td>\n",
       "      <td>3358.622070</td>\n",
       "      <td>152.876547</td>\n",
       "      <td>90.235726</td>\n",
       "      <td>259.080172</td>\n",
       "      <td>4991.784669</td>\n",
       "      <td>255</td>\n",
       "      <td>1107119177</td>\n",
       "      <td>1047442890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449454</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>254</td>\n",
       "      <td>252</td>\n",
       "      <td>8561.499023</td>\n",
       "      <td>3987.059814</td>\n",
       "      <td>47.750333</td>\n",
       "      <td>75.659602</td>\n",
       "      <td>2415.837634</td>\n",
       "      <td>115.807000</td>\n",
       "      <td>255</td>\n",
       "      <td>2436137549</td>\n",
       "      <td>1977154190</td>\n",
       "      <td>0.128381</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3db7a911-4962-4757-bfee-a7e8cd4d7dc5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3db7a911-4962-4757-bfee-a7e8cd4d7dc5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3db7a911-4962-4757-bfee-a7e8cd4d7dc5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-3b18f396-4844-44f5-a558-54b847197ab2\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b18f396-4844-44f5-a558-54b847197ab2')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-3b18f396-4844-44f5-a558-54b847197ab2 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts       rate  sttl  dttl         sload          dload      sinpkt      dinpkt          sjit          djit  swin       stcpb       dtcpb    tcprtt  smean  dmean  trans_depth  response_body_len  ct_srv_src  ct_state_ttl  ct_dst_ltm  is_ftp_login  ct_flw_http_mthd  attack_cat\n",
       "0  0.121478    113        1      2      6      4  74.087490   252   254  14158.942380    8495.365234   24.295600    8.375000     30.177547     11.830604   255   621772692  2202533631  0.000000     43     43            0                  0           1             0           1             0                 0           4\n",
       "1  0.649902    113        1      2     14     38  78.473372    62   252   8395.112305  503571.312500   49.915000   15.432865     61.426934   1387.778330   255  1417884146  3077387971  0.000000     52   1106            0                  0          43             1           1             0                 0           4\n",
       "2  1.623129    113        1      2      8     16  14.170161    62   252   1572.271851   60929.230470  231.875571  102.737203  17179.586860  11420.926230   255  2116150707  2963114973  0.111897     46    824            0                  0           7             1           2             0                 0           4\n",
       "3  1.681642    113        2      2     12     12  13.677108    62   252   2740.178955    3358.622070  152.876547   90.235726    259.080172   4991.784669   255  1107119177  1047442890  0.000000     52     64            0                  0           1             1           2             1                 0           4\n",
       "4  0.449454    113        1      2     10      6  33.373826   254   252   8561.499023    3987.059814   47.750333   75.659602   2415.837634    115.807000   255  2436137549  1977154190  0.128381     53     45            0                  0          43             1           2             0                 0           4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bTVtBkj_I8ri",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "bTVtBkj_I8ri",
    "outputId": "5c01dc01-da6f-4781-dfa6-37be8cec9da5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "test_filtered"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-66837c98-9d4a-435b-b72c-38515d0c2181\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>180363632.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>881000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>854400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>600000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>850400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66837c98-9d4a-435b-b72c-38515d0c2181')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-66837c98-9d4a-435b-b72c-38515d0c2181 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-66837c98-9d4a-435b-b72c-38515d0c2181');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-f90a4c26-54f6-453c-a1cb-601363f75210\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f90a4c26-54f6-453c-a1cb-601363f75210')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-f90a4c26-54f6-453c-a1cb-601363f75210 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts         rate  sttl  dttl        sload  dload  sinpkt  dinpkt  sjit  djit  swin  stcpb  dtcpb  tcprtt  smean  dmean  trans_depth  response_body_len  ct_srv_src  ct_state_ttl  ct_dst_ltm  is_ftp_login  ct_flw_http_mthd  attack_cat\n",
       "0  0.000011    117        1      4      2      0   90909.0902   254     0  180363632.0    0.0   0.011     0.0   0.0   0.0     0      0      0     0.0    248      0            0                  0           2             2           1             0                 0           4\n",
       "1  0.000008    117        1      4      2      0  125000.0003   254     0  881000000.0    0.0   0.008     0.0   0.0   0.0     0      0      0     0.0    881      0            0                  0           2             2           1             0                 0           4\n",
       "2  0.000005    117        1      4      2      0  200000.0051   254     0  854400000.0    0.0   0.005     0.0   0.0   0.0     0      0      0     0.0    534      0            0                  0           3             2           1             0                 0           4\n",
       "3  0.000006    117        1      4      2      0  166666.6608   254     0  600000000.0    0.0   0.006     0.0   0.0   0.0     0      0      0     0.0    450      0            0                  0           3             2           2             0                 0           4\n",
       "4  0.000010    117        1      4      2      0  100000.0025   254     0  850400000.0    0.0   0.010     0.0   0.0   0.0     0      0      0     0.0   1063      0            0                  0           3             2           2             0                 0           4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "zs2WRy56-YMc",
   "metadata": {
    "id": "zs2WRy56-YMc"
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "X_train = train_filtered.drop(columns=['attack_cat'])\n",
    "y_train = y_train_encoded\n",
    "\n",
    "#Test\n",
    "X_test = test_filtered.drop(columns=['attack_cat'])\n",
    "y_test = y_test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JC4IUIYWvd9Z",
   "metadata": {
    "id": "JC4IUIYWvd9Z"
   },
   "source": [
    "#Traditional Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XLDvELrtvRfZ",
   "metadata": {
    "id": "XLDvELrtvRfZ"
   },
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pgydwo6SSlew",
   "metadata": {
    "id": "Pgydwo6SSlew"
   },
   "source": [
    "*   In our traditional learning methods, first we are planning to go with Logistic regression which is the oldest classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D_X1IpC5FJ0s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_X1IpC5FJ0s",
    "outputId": "6d0a73bb-1496-4f76-8d3d-c7a9448ac8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.00      0.00     12264\n",
      "           1       0.37      0.72      0.49     33393\n",
      "           2       0.46      0.16      0.24     18184\n",
      "           3       0.82      0.98      0.89     40000\n",
      "           4       0.79      0.72      0.75     56000\n",
      "           5       0.00      0.00      0.00     10491\n",
      "\n",
      "    accuracy                           0.63    170332\n",
      "   macro avg       0.45      0.43      0.40    170332\n",
      "weighted avg       0.59      0.63      0.58    170332\n",
      "\n",
      "Testing Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.00      0.00      4089\n",
      "           1       0.24      0.69      0.35     11132\n",
      "           2       0.24      0.14      0.18      6062\n",
      "           3       0.78      0.96      0.86     18871\n",
      "           4       0.81      0.47      0.59     37000\n",
      "           5       0.00      0.00      0.00      3496\n",
      "\n",
      "    accuracy                           0.55     80650\n",
      "   macro avg       0.40      0.38      0.33     80650\n",
      "weighted avg       0.62      0.55      0.54     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize LogisticRegression\n",
    "logreg = LogisticRegression(penalty = 'none', max_iter = 10000) # Instantiating llogistic regression\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#predict on train data\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "# Print classification report for train data\n",
    "print(\"Training Classification Report\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "# Print classification report for test data\n",
    "print(\"Testing Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "COOyFhX-BTAu",
   "metadata": {
    "id": "COOyFhX-BTAu"
   },
   "source": [
    "\n",
    "\n",
    "*   We could see that,for this logistic regression model there is no variance, but there is bias.\n",
    "*   since our problem is multi classification problem, our focus is not only on accuracy because as we know accuracy is a metric that is defined for the classification altogether but it is not defined for\n",
    "classes individually.\n",
    "*  and also  in dealing with unbalanced classification problems, a accuracy alone does not mean anything, that's why we have other metrics like precision, recall, and f1-score that are defined for each class of the classification problem.\n",
    "*   Even though, all four of them work together to evaluate\n",
    "the performance of a classifier, our main focus is on F1-score because F1-\n",
    "score is the harmonic mean of the precision and recall for each class and also  Achieving a high F1-score requires both high precision and high recall.\n",
    "*    Model is performing good for classes 1, 3, and 4 which are majority classes compared to minority classes 0, 2, and 5.\n",
    "*   To address this class imbalance, we tried below methods:\n",
    "    1.   Class Weighting\n",
    "    2.   Resampling Techniques\n",
    "    3.   Ensemble Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ra4fK5iY9-sE",
   "metadata": {
    "id": "Ra4fK5iY9-sE"
   },
   "source": [
    "#Balanced Logistic Regression or Logistic Regression with Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N4pnFNHABCrL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4pnFNHABCrL",
    "outputId": "345d88d5-f22d-46c3-bcac-c569d07023fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.69      0.44     12264\n",
      "           1       0.33      0.13      0.19     33393\n",
      "           2       0.28      0.78      0.41     18184\n",
      "           3       0.89      0.98      0.93     40000\n",
      "           4       0.91      0.59      0.71     56000\n",
      "           5       0.00      0.00      0.00     10491\n",
      "\n",
      "    accuracy                           0.58    170332\n",
      "   macro avg       0.45      0.53      0.45    170332\n",
      "weighted avg       0.63      0.58      0.57    170332\n",
      "\n",
      "Testing Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.61      0.40      4089\n",
      "           1       0.32      0.17      0.22     11132\n",
      "           2       0.15      0.71      0.24      6062\n",
      "           3       0.83      0.96      0.89     18871\n",
      "           4       0.91      0.37      0.53     37000\n",
      "           5       0.00      0.00      0.00      3496\n",
      "\n",
      "    accuracy                           0.50     80650\n",
      "   macro avg       0.42      0.47      0.38     80650\n",
      "weighted avg       0.68      0.50      0.52     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize LogisticRegression with balanced class weights\n",
    "logreg = LogisticRegression(penalty='none', max_iter=10000, class_weight='balanced')\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#predict on train data\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "# Print classification report for train data\n",
    "print(\"Training Classification Report\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "# Print classification report for test data\n",
    "print(\"Testing Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G9bnWhU7Y_P2",
   "metadata": {
    "id": "G9bnWhU7Y_P2"
   },
   "source": [
    "By balanced class weighting, we can penalize misclassifications of the minority classes more heavily than the majority classes. By giving higher weights to minority classes, we can encourage the model to pay more attention to these classes during training. In here, we could see there is slight improvement in F1-score for minority classes 0 and 2. But for class 5 there is no impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZrWbFCh22M_m",
   "metadata": {
    "id": "ZrWbFCh22M_m"
   },
   "source": [
    "#Logistic Regression with SMOTE(Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccqPtpC1eDB_",
   "metadata": {
    "id": "ccqPtpC1eDB_"
   },
   "source": [
    "*   SMOTE (Synthetic Minority Over-sampling Technique) is a popular technique used to address class imbalance in machine learning datasets. It works by generating synthetic samples for the minority class to balance the class distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EzNXrkHr2oH1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzNXrkHr2oH1",
    "outputId": "cd999f8d-8620-44c8-c974-5a4d8a00db2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report after SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.74      0.21     12264\n",
      "           1       0.00      0.00      0.00     33393\n",
      "           2       0.19      0.57      0.29     18184\n",
      "           3       0.01      0.00      0.00     40000\n",
      "           4       0.81      0.60      0.69     56000\n",
      "           5       0.00      0.00      0.00     10491\n",
      "\n",
      "    accuracy                           0.31    170332\n",
      "   macro avg       0.19      0.32      0.20    170332\n",
      "weighted avg       0.30      0.31      0.27    170332\n",
      "\n",
      "Training Confusion Matrix after SMOTE:\n",
      "[[ 9103     0  2427    88   646     0]\n",
      " [12116     0 16633   180  4464     0]\n",
      " [ 5880     0 10417    20  1867     0]\n",
      " [39464     0   386     3   147     0]\n",
      " [ 3365     0 19125    14 33496     0]\n",
      " [ 5186     0  4459    27   819     0]]\n",
      "Testing Classification Report after SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.68      0.15      4089\n",
      "           1       0.00      0.00      0.00     11132\n",
      "           2       0.11      0.54      0.18      6062\n",
      "           3       0.20      0.00      0.00     18871\n",
      "           4       0.83      0.42      0.56     37000\n",
      "           5       0.00      0.00      0.00      3496\n",
      "\n",
      "    accuracy                           0.27     80650\n",
      "   macro avg       0.21      0.27      0.15     80650\n",
      "weighted avg       0.44      0.27      0.28     80650\n",
      "\n",
      "Testing Confusion Matrix after SMOTE:\n",
      "[[ 2770     0   979    45   295     0]\n",
      " [ 3040     0  6267    18  1807     0]\n",
      " [ 2240     0  3252     2   568     0]\n",
      " [18300     0   388    18   165     0]\n",
      " [ 4651     1 16782     4 15562     0]\n",
      " [ 1593     0  1622     2   279     0]]\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train Logistic Regression on the resampled data\n",
    "logistic_reg_smote = LogisticRegression()\n",
    "logistic_reg_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate the model\n",
    "y_train_pred_sm = logistic_reg_smote.predict(X_train)\n",
    "y_test_pred_sm = logistic_reg_smote.predict(X_test)\n",
    "\n",
    "print(\"Training Classification Report after SMOTE:\")\n",
    "print(classification_report(y_train, y_train_pred_sm))\n",
    "\n",
    "print(\"Training Confusion Matrix after SMOTE:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_sm))\n",
    "\n",
    "print(\"Testing Classification Report after SMOTE:\")\n",
    "print(classification_report(y_test, y_test_pred_sm ))\n",
    "\n",
    "print(\"Testing Confusion Matrix after SMOTE:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X0WVYp7Na4Ar",
   "metadata": {
    "id": "X0WVYp7Na4Ar"
   },
   "source": [
    "\n",
    "\n",
    "*   After applying SMOTE technique, we could see except class 4, results of remaining all the classes have been very low\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xM3WMschwEAj",
   "metadata": {
    "id": "xM3WMschwEAj"
   },
   "source": [
    "#Logistic Regression with Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MZTHwPUdhomp",
   "metadata": {
    "id": "MZTHwPUdhomp"
   },
   "source": [
    "\n",
    "\n",
    "*   By identifying the best combination of hyperparameters, GridSearchCV helps to maximize model performance. This can lead to better predictive accuracy, higher precision, improved recall, or other performance metrics. We want to give a try for grid search by imposing penalities and see how we will get the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k3Awna1drP1w",
   "metadata": {
    "id": "k3Awna1drP1w"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.003, 0.005, 0.009],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2']  # Penalty term\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dq821R-criWy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "Dq821R-criWy",
    "outputId": "8ddaaae9-2951-4d71-9067-9d223a812808"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=3000),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.003, 0.005, 0.009],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=3000),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.003, 0.005, 0.009],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=3000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=3000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=3000),\n",
       "             param_grid={'C': [0.001, 0.003, 0.005, 0.009],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Grid Search Cross-Validation\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=3000), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tSR__Prtr9qi",
   "metadata": {
    "id": "tSR__Prtr9qi"
   },
   "outputs": [],
   "source": [
    "# Retrain the model with the best hyperparameters\n",
    "best_log_reg_model = grid_search.best_estimator_\n",
    "best_log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_cv = best_log_reg_model.predict(X_train)\n",
    "y_test_pred_cv = best_log_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fkuYZFYSsCMa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkuYZFYSsCMa",
    "outputId": "e6df5aca-8288-48bc-b5aa-e61a344c3c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report after Hyperparameter Optimization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12264\n",
      "           1       0.37      0.72      0.49     33393\n",
      "           2       0.46      0.16      0.23     18184\n",
      "           3       0.82      0.98      0.89     40000\n",
      "           4       0.79      0.72      0.75     56000\n",
      "           5       0.00      0.00      0.00     10491\n",
      "\n",
      "    accuracy                           0.63    170332\n",
      "   macro avg       0.41      0.43      0.39    170332\n",
      "weighted avg       0.57      0.63      0.58    170332\n",
      "\n",
      "Training Confusion Matrix after Hyperparameter Optimization:\n",
      "[[    0 10070   334   468  1392     0]\n",
      " [    0 23948   659   736  8050     0]\n",
      " [    2 12511  2857  1992   822     0]\n",
      " [    0   499    96 39139   266     0]\n",
      " [    0 11655  2142  1649 40554     0]\n",
      " [    0  6397    64  3676   354     0]]\n",
      "Testing Classification Report after Hyperparameter Optimization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4089\n",
      "           1       0.24      0.69      0.35     11132\n",
      "           2       0.24      0.14      0.18      6062\n",
      "           3       0.78      0.96      0.86     18871\n",
      "           4       0.80      0.47      0.59     37000\n",
      "           5       0.00      0.00      0.00      3496\n",
      "\n",
      "    accuracy                           0.55     80650\n",
      "   macro avg       0.34      0.38      0.33     80650\n",
      "weighted avg       0.60      0.55      0.54     80650\n",
      "\n",
      "Testing Confusion Matrix after Hyperparameter Optimization:\n",
      "[[    0  3188   129   232   540     0]\n",
      " [    0  7633   194   215  3090     0]\n",
      " [    0  4581   849   411   221     0]\n",
      " [    0   306   100 18187   278     0]\n",
      " [    0 14371  2320  2845 17464     0]\n",
      " [    0  2043    13  1327   113     0]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Training Classification Report after Hyperparameter Optimization:\")\n",
    "print(classification_report(y_train, y_train_pred_cv))\n",
    "\n",
    "print(\"Training Confusion Matrix after Hyperparameter Optimization:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_cv))\n",
    "\n",
    "print(\"Testing Classification Report after Hyperparameter Optimization:\")\n",
    "print(classification_report(y_test, y_test_pred_cv))\n",
    "\n",
    "print(\"Testing Confusion Matrix after Hyperparameter Optimization:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BAjq2yTPcCHa",
   "metadata": {
    "id": "BAjq2yTPcCHa"
   },
   "source": [
    "\n",
    "\n",
    "*   Grid Search has given me the same results that we have got for our base logistic regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jPEu-q3YK33Q",
   "metadata": {
    "id": "jPEu-q3YK33Q"
   },
   "source": [
    "\n",
    "\n",
    "*  After performing Logistic regression with all these possibilities, We want to conclude that Logist regression model is not a good fit for our problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5kxtNYkXwdkd",
   "metadata": {
    "id": "5kxtNYkXwdkd"
   },
   "source": [
    "#Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-fNuZ6DUpnhu",
   "metadata": {
    "id": "-fNuZ6DUpnhu"
   },
   "source": [
    "\n",
    "\n",
    "*   A decision tree is a hierarchical tree-like structure where each node represents a feature, each branch represents a decision based on that feature, and each leaf node represents the outcome\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zlAcZ7yNyNzQ",
   "metadata": {
    "id": "zlAcZ7yNyNzQ"
   },
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_train_pred_dt = dt_classifier.predict(X_train)\n",
    "y_test_pred_dt = dt_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CB0ev7zkyS2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CB0ev7zkyS2f",
    "outputId": "d091f3fb-d07b-41b0-c15c-bba4ceba034e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Decision Tree on Train Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.46      0.51     12264\n",
      "           1       0.77      0.91      0.83     33393\n",
      "           2       0.96      0.91      0.93     18184\n",
      "           3       1.00      0.99      1.00     40000\n",
      "           4       1.00      0.99      0.99     56000\n",
      "           5       1.00      0.82      0.90     10491\n",
      "\n",
      "    accuracy                           0.92    170332\n",
      "   macro avg       0.88      0.85      0.86    170332\n",
      "weighted avg       0.92      0.92      0.92    170332\n",
      "\n",
      "\n",
      "Classification Report for Decision Tree on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.36      0.33      4089\n",
      "           1       0.62      0.69      0.65     11132\n",
      "           2       0.28      0.52      0.36      6062\n",
      "           3       0.98      0.97      0.97     18871\n",
      "           4       0.92      0.74      0.82     37000\n",
      "           5       0.83      0.78      0.81      3496\n",
      "\n",
      "    accuracy                           0.75     80650\n",
      "   macro avg       0.65      0.68      0.66     80650\n",
      "weighted avg       0.81      0.75      0.77     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Decision Tree on Train Data:\\n\", classification_report(y_train, y_train_pred_dt))\n",
    "print(\"\\nClassification Report for Decision Tree on Test Data:\\n\", classification_report(y_test, y_test_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96_OYOCQqMVi",
   "metadata": {
    "id": "96_OYOCQqMVi"
   },
   "source": [
    "\n",
    "\n",
    "*   We could see, we are getting better scores for all the classes for decision tree classifier model.\n",
    "*   Drawbacks of decision trees is that they typically\n",
    "suffer from high variance. As we can see above, there is a huge difference between accuracies of train and test data. To address this issue, we will try to implement pruning techniques such as setting constraints on the depth of the tree or the minimum samples split and Minimum Samples Leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qGUva4MJFYOE",
   "metadata": {
    "id": "qGUva4MJFYOE"
   },
   "source": [
    "#Decision tree classifier with pruning techniques such as setting constraints on the depth of the tree or the minimum samples split and Minimum Samples Leaf to reduce variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kj_MKoLac2yh",
   "metadata": {
    "id": "Kj_MKoLac2yh"
   },
   "source": [
    "->**max_depth**: This parameter controls the maximum depth of the decision tree. The depth of a tree corresponds to the length of the longest path from the root node to a leaf node. Setting max_depth limits the depth of the tree, which helps prevent overfitting.\n",
    "\n",
    "->**min_samples_split**: This parameter specifies the minimum number of samples required to split an internal node. If a node has fewer samples than min_samples_split, it will not be split, and it will become a leaf node. Setting a higher value for min_samples_split can help prevent the tree from splitting too early, which can lead to overfitting.\n",
    "\n",
    "->**min_samples_leaf**: This parameter sets the minimum number of samples required to be at a leaf node. If a split results in a leaf node containing fewer samples than min_samples_leaf, the split is not considered valid, and the node will not be further split. Setting a higher value for min_samples_leaf can help prevent overfitting by requiring each leaf node to have a minimum number of samples.\n",
    "\n",
    "->**random_state**: This parameter controls the randomness of the estimator. By setting a specific value for random_state, you ensure that the results are reproducible across multiple runs. If you use the same random_state value in different runs, you'll get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cO9P_jCmE3vT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cO9P_jCmE3vT",
    "outputId": "f7905c45-17ba-42cc-e7b1-18fc5f99efd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Decision Tree on Train Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.05      0.08     12264\n",
      "           1       0.64      0.92      0.76     33393\n",
      "           2       0.65      0.62      0.63     18184\n",
      "           3       1.00      0.97      0.98     40000\n",
      "           4       0.90      0.91      0.90     56000\n",
      "           5       0.89      0.75      0.81     10491\n",
      "\n",
      "    accuracy                           0.82    170332\n",
      "   macro avg       0.78      0.70      0.70    170332\n",
      "weighted avg       0.82      0.82      0.80    170332\n",
      "\n",
      "\n",
      "Classification Report for Decision Tree on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.07      0.09      4089\n",
      "           1       0.57      0.86      0.68     11132\n",
      "           2       0.28      0.52      0.36      6062\n",
      "           3       1.00      0.74      0.85     18871\n",
      "           4       0.81      0.72      0.76     37000\n",
      "           5       0.86      0.79      0.82      3496\n",
      "\n",
      "    accuracy                           0.70     80650\n",
      "   macro avg       0.61      0.62      0.60     80650\n",
      "weighted avg       0.75      0.70      0.71     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize DecisionTreeClassifier with combined parameters to reduce variance\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=10, min_samples_split=5, min_samples_leaf=5, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred_dt = dt_classifier.predict(X_train)\n",
    "y_test_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "print(\"Classification Report for Decision Tree on Train Data:\\n\", classification_report(y_train, y_train_pred_dt))\n",
    "print(\"\\nClassification Report for Decision Tree on Test Data:\\n\", classification_report(y_test, y_test_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J8Udpu68o9jX",
   "metadata": {
    "id": "J8Udpu68o9jX"
   },
   "source": [
    "\n",
    "\n",
    "*   After implementing this pruning techniques, we are able to reduce variance slightly, but scores of minority class 0 has decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7k_9zZ8fyWwS",
   "metadata": {
    "id": "7k_9zZ8fyWwS"
   },
   "source": [
    "#Decision Tree Classifier with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pqjHY1IoylRL",
   "metadata": {
    "id": "pqjHY1IoylRL"
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [1,2,3,4,5,6,7,8,9,10,12,13,14,15,16,17,18,19,20],\n",
    "    'min_samples_split': [1,2,3,4,5,6,7,8,9,10,12,13,14,15,16,17,18,19,20],\n",
    "    'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10,12,13,14,15,16,17,18,19,20],\n",
    "    'ccp_alpha': [0.001, 0.003, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C0DYUFFwzJIe",
   "metadata": {
    "id": "C0DYUFFwzJIe"
   },
   "outputs": [],
   "source": [
    "# Retrain the model with the best hyperparameters\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_cv = best_dt_model.predict(X_train)\n",
    "y_test_pred_cv = best_dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sm6oxjrCzzAK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sm6oxjrCzzAK",
    "outputId": "0d40bb4b-e21e-44ea-9560-b2a8930c95e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report after Hyperparameter Optimization:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12264\n",
      "           1       0.53      0.89      0.67     33393\n",
      "           2       0.30      0.49      0.37     18184\n",
      "           3       1.00      0.91      0.95     40000\n",
      "           4       0.95      0.82      0.88     56000\n",
      "           5       0.00      0.00      0.00     10491\n",
      "\n",
      "    accuracy                           0.71    170332\n",
      "   macro avg       0.46      0.52      0.48    170332\n",
      "weighted avg       0.68      0.71      0.68    170332\n",
      "\n",
      "Training Confusion Matrix after Hyperparameter Optimization:\n",
      "[[    0 11101   939     0   224     0]\n",
      " [    0 29798  2610     3   982     0]\n",
      " [    0  8411  8891     3   879     0]\n",
      " [    0   757  2666 36545    32     0]\n",
      " [    0  3891  6348     5 45756     0]\n",
      " [    0  2148  8270     0    73     0]]\n",
      "Testing Classification Report after Hyperparameter Optimization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4089\n",
      "           1       0.42      0.82      0.55     11132\n",
      "           2       0.12      0.42      0.19      6062\n",
      "           3       1.00      0.67      0.80     18871\n",
      "           4       0.90      0.60      0.72     37000\n",
      "           5       0.00      0.00      0.00      3496\n",
      "\n",
      "    accuracy                           0.58     80650\n",
      "   macro avg       0.41      0.42      0.38     80650\n",
      "weighted avg       0.72      0.58      0.61     80650\n",
      "\n",
      "Testing Confusion Matrix after Hyperparameter Optimization:\n",
      "[[    0  3400   421     0   268     0]\n",
      " [    0  9092   869     2  1169     0]\n",
      " [    0  2660  2567     2   833     0]\n",
      " [    0   566  5601 12661    43     0]\n",
      " [    0  5566  9152     0 22282     0]\n",
      " [    0   489  2978     0    29     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Training Classification Report after Hyperparameter Optimization:\")\n",
    "print(classification_report(y_train, y_train_pred_cv))\n",
    "\n",
    "print(\"Training Confusion Matrix after Hyperparameter Optimization:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_cv))\n",
    "\n",
    "print(\"Testing Classification Report after Hyperparameter Optimization:\")\n",
    "print(classification_report(y_test, y_test_pred_cv))\n",
    "\n",
    "print(\"Testing Confusion Matrix after Hyperparameter Optimization:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yx9jY1v9LS5e",
   "metadata": {
    "id": "yx9jY1v9LS5e"
   },
   "source": [
    "* After performing decision tree with grid search, we could see it is performing good for all the classes, except the minority classes 0 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t752O8JMuEl2",
   "metadata": {
    "id": "t752O8JMuEl2"
   },
   "source": [
    "\n",
    "\n",
    "*   After performing decision tree classifier, based on the results we want to conclude it by saying that Decision tree classifier is the best fit for our problem. Here, we didn't faced the challenge of increasing metrics scores for classes, but we have faced the challenge of addressing variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pZc6sAH4zxU5",
   "metadata": {
    "id": "pZc6sAH4zxU5"
   },
   "source": [
    "#Ensemble Learning Methods\n",
    "##Ensemble methods like Random Forest or Gradient Boosting can handle class imbalance better than single Decision Trees by aggregating the predictions of multiple trees and also help in reducing overfitting by aggregating the predictions of multiple trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fUMPip8a0MzN",
   "metadata": {
    "id": "fUMPip8a0MzN"
   },
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cLv5dQjlAAxU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLv5dQjlAAxU",
    "outputId": "ddee8d58-663a-4212-c871-8b8a9ec9e920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score : 0.7897\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on the test set results\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Check accuracy score\n",
    "\n",
    "print('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T8kGghngshqq",
   "metadata": {
    "id": "T8kGghngshqq"
   },
   "source": [
    "Classification Report on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fl0qUMymGenl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fl0qUMymGenl",
    "outputId": "04f0250c-8f73-40ca-ac69-d188cc6d7b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.39      0.48     12264\n",
      "           1       0.75      0.94      0.83     33393\n",
      "           2       0.96      0.91      0.93     18184\n",
      "           3       1.00      0.99      1.00     40000\n",
      "           4       1.00      0.99      0.99     56000\n",
      "           5       0.99      0.82      0.90     10491\n",
      "\n",
      "    accuracy                           0.92    170332\n",
      "   macro avg       0.89      0.84      0.86    170332\n",
      "weighted avg       0.92      0.92      0.91    170332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H01sfXEbuEw5",
   "metadata": {
    "id": "H01sfXEbuEw5"
   },
   "source": [
    "Classification Report on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dICW1hKmJ7yI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dICW1hKmJ7yI",
    "outputId": "51f273b3-8b8a-4455-9fb4-5a590a6f6dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.19      0.28      4089\n",
      "           1       0.63      0.86      0.73     11132\n",
      "           2       0.29      0.57      0.39      6062\n",
      "           3       1.00      0.97      0.98     18871\n",
      "           4       0.94      0.78      0.85     37000\n",
      "           5       0.92      0.79      0.85      3496\n",
      "\n",
      "    accuracy                           0.79     80650\n",
      "   macro avg       0.71      0.69      0.68     80650\n",
      "weighted avg       0.84      0.79      0.80     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VpDFyEi5MkiF",
   "metadata": {
    "id": "VpDFyEi5MkiF"
   },
   "source": [
    "*Based on the above classification report, there is some what reduction in the variance, but still there is notable difference in performance between the test and train data, suggesting potential overfitting to the train data, as indicated by the higher performance metrics on the train data compared to the test data. To address this, we have tried following parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ghZTbl2bme2q",
   "metadata": {
    "id": "ghZTbl2bme2q"
   },
   "source": [
    "# Random Forest code with regularization and feature sampling to reduce variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ur0UNfnhgNvK",
   "metadata": {
    "id": "Ur0UNfnhgNvK"
   },
   "source": [
    "->**n_estimators**: This parameter determines the number of decision trees in the random forest. Each tree in the forest is trained on a random subset of the training data. Increasing the number of estimators generally improves the performance of the random forest, up to a certain point, by reducing overfitting and increasing the model's ability to generalize.\n",
    "\n",
    "->**max_features**: This parameter determines the maximum number of features to consider when looking for the best split in each decision tree. It can be set to different values such as 'sqrt' (square root of the total number of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "x-JvUILfl2p8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-JvUILfl2p8",
    "outputId": "d1104fd8-6468-43d3-bc56-4f69baaaf6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.02      0.03     12264\n",
      "           1       0.64      0.95      0.76     33393\n",
      "           2       0.64      0.79      0.71     18184\n",
      "           3       1.00      0.98      0.99     40000\n",
      "           4       0.96      0.87      0.91     56000\n",
      "           5       0.90      0.67      0.77     10491\n",
      "\n",
      "    accuracy                           0.83    170332\n",
      "   macro avg       0.85      0.71      0.70    170332\n",
      "weighted avg       0.87      0.83      0.81    170332\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.01      0.03      4089\n",
      "           1       0.59      0.93      0.72     11132\n",
      "           2       0.28      0.63      0.38      6062\n",
      "           3       1.00      0.96      0.98     18871\n",
      "           4       0.96      0.72      0.82     37000\n",
      "           5       0.80      0.73      0.76      3496\n",
      "\n",
      "    accuracy                           0.76     80650\n",
      "   macro avg       0.73      0.66      0.62     80650\n",
      "weighted avg       0.85      0.76      0.77     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize RandomForestClassifier with regularization and feature sampling\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_depth=10,\n",
    "                             min_samples_split=5,\n",
    "                             min_samples_leaf=2,\n",
    "                             max_features='sqrt',\n",
    "                             random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84A3mJyxCNRb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "84A3mJyxCNRb",
    "outputId": "fc9c8ba3-f2ef-44e5-c6a1-cd8845b7420a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={&#x27;max_depth&#x27;: [100, 200, 300],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={&#x27;max_depth&#x27;: [100, 200, 300],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={'max_depth': [100, 200, 300],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier with Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [100,200,300],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1,2,4],\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "SirQO-6RCbCx",
   "metadata": {
    "id": "SirQO-6RCbCx"
   },
   "outputs": [],
   "source": [
    "# Retrain the model with the best hyperparameters\n",
    "best_clf_model = grid_search.best_estimator_\n",
    "best_clf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_cv = best_clf_model.predict(X_train)\n",
    "y_test_pred_cv = best_clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fqJVz-AICzW1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqJVz-AICzW1",
    "outputId": "aa50e08d-6b00-4977-e66a-66be38b9c9ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report after Hyperparameter Optimization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.23      0.32     12264\n",
      "           1       0.71      0.93      0.80     33393\n",
      "           2       0.86      0.87      0.87     18184\n",
      "           3       1.00      0.98      0.99     40000\n",
      "           4       0.98      0.96      0.97     56000\n",
      "           5       0.97      0.80      0.88     10491\n",
      "\n",
      "    accuracy                           0.89    170332\n",
      "   macro avg       0.85      0.80      0.81    170332\n",
      "weighted avg       0.89      0.89      0.88    170332\n",
      "\n",
      "Training Confusion Matrix after Hyperparameter Optimization:\n",
      "[[ 2793  9130   188     5    77    71]\n",
      " [ 1536 31173   380     1   196   107]\n",
      " [  230  1372 15890     4   651    37]\n",
      " [  154   472    84 39265    21     4]\n",
      " [    8   200  1985     1 53759    47]\n",
      " [  310  1759    17     1    11  8393]]\n",
      "Testing Classification Report after Hyperparameter Optimization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.16      0.24      4089\n",
      "           1       0.61      0.90      0.73     11132\n",
      "           2       0.30      0.57      0.40      6062\n",
      "           3       1.00      0.96      0.98     18871\n",
      "           4       0.95      0.78      0.85     37000\n",
      "           5       0.93      0.79      0.85      3496\n",
      "\n",
      "    accuracy                           0.79     80650\n",
      "   macro avg       0.71      0.69      0.67     80650\n",
      "weighted avg       0.84      0.79      0.80     80650\n",
      "\n",
      "Testing Confusion Matrix after Hyperparameter Optimization:\n",
      "[[  639  3205   136     1    70    38]\n",
      " [  424  9983   361     3   226   135]\n",
      " [  166  1096  3466     5  1322     7]\n",
      " [   38   519    96 18192    23     3]\n",
      " [   12   884  7375     4 28690    35]\n",
      " [   45   611    50     1    27  2762]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Training Classification Report after Hyperparameter Optimization:\")\n",
    "print(classification_report(y_train, y_train_pred_cv))\n",
    "\n",
    "print(\"Training Confusion Matrix after Hyperparameter Optimization:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_cv))\n",
    "\n",
    "print(\"Testing Classification Report after Hyperparameter Optimization:\")\n",
    "print(classification_report(y_test, y_test_pred_cv))\n",
    "\n",
    "print(\"Testing Confusion Matrix after Hyperparameter Optimization:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n29BoR9l0Q_g",
   "metadata": {
    "id": "n29BoR9l0Q_g"
   },
   "source": [
    "\n",
    "\n",
    "*   After adding the regularization and feature sampling hyper parameters, we could there is significant reduction in variance. Here also just like decision trees, metric scores of class 0 has decreased while we are trying to reduce variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dQxbB5D7zZm4",
   "metadata": {
    "id": "dQxbB5D7zZm4"
   },
   "source": [
    "#Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Oc79e_gW3n2y",
   "metadata": {
    "id": "Oc79e_gW3n2y"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "y_train_pred_gb = gb_classifier.predict(X_train)\n",
    "y_test_pred_gb = gb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7SmJIAlY3zDe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SmJIAlY3zDe",
    "outputId": "e4dc9d59-6a10-4693-fc68-e2c0a5c059b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Gradient Boosting on Train Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.02      0.04     12264\n",
      "           1       0.64      0.93      0.76     33393\n",
      "           2       0.68      0.72      0.70     18184\n",
      "           3       1.00      0.98      0.99     40000\n",
      "           4       0.93      0.90      0.92     56000\n",
      "           5       0.90      0.76      0.82     10491\n",
      "\n",
      "    accuracy                           0.83    170332\n",
      "   macro avg       0.82      0.72      0.70    170332\n",
      "weighted avg       0.85      0.83      0.81    170332\n",
      "\n",
      "\n",
      "Classification Report for Gradient Boosting on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.06      0.10      4089\n",
      "           1       0.46      0.93      0.62     11132\n",
      "           2       0.30      0.55      0.39      6062\n",
      "           3       1.00      0.96      0.98     18871\n",
      "           4       0.97      0.67      0.79     37000\n",
      "           5       0.92      0.78      0.84      3496\n",
      "\n",
      "    accuracy                           0.74     80650\n",
      "   macro avg       0.67      0.66      0.62     80650\n",
      "weighted avg       0.82      0.74      0.75     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Gradient Boosting\n",
    "print(\"Classification Report for Gradient Boosting on Train Data:\\n\", classification_report(y_train, y_train_pred_gb))\n",
    "print(\"\\nClassification Report for Gradient Boosting on Test Data:\\n\", classification_report(y_test, y_test_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AyzmWhA2MRWt",
   "metadata": {
    "id": "AyzmWhA2MRWt"
   },
   "source": [
    "* We could see, Gradient boosting is also performing good for all the classes except class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xbhQLv8ijoDL",
   "metadata": {
    "id": "xbhQLv8ijoDL"
   },
   "source": [
    "#Xtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FFR6bX-A-qbB",
   "metadata": {
    "id": "FFR6bX-A-qbB"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# Fit grid search to the training data\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_xgb = xgb_classifier.predict(X_train)\n",
    "y_test_pred_xgb = xgb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KHI-1xP9-0Hd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHI-1xP9-0Hd",
    "outputId": "85a572c9-08ef-4504-da7c-52b2d06d0e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.11      0.20     12264\n",
      "           1       0.68      0.95      0.79     33393\n",
      "           2       0.78      0.79      0.79     18184\n",
      "           3       1.00      0.99      0.99     40000\n",
      "           4       0.95      0.93      0.94     56000\n",
      "           5       0.95      0.78      0.86     10491\n",
      "\n",
      "    accuracy                           0.87    170332\n",
      "   macro avg       0.85      0.76      0.76    170332\n",
      "weighted avg       0.88      0.87      0.85    170332\n",
      "\n",
      "Training Confusion Matrix:\n",
      "[[ 1395 10566   163     5    85    50]\n",
      " [  340 31881   502    21   318   331]\n",
      " [   45  1605 14412     9  2084    29]\n",
      " [    9   434    67 39473    15     2]\n",
      " [    8   287  3323     1 52342    39]\n",
      " [   74  2190    13     1     4  8209]]\n",
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.17      0.24      4089\n",
      "           1       0.62      0.88      0.72     11132\n",
      "           2       0.28      0.76      0.41      6062\n",
      "           3       1.00      0.97      0.98     18871\n",
      "           4       0.98      0.66      0.79     37000\n",
      "           5       0.94      0.79      0.86      3496\n",
      "\n",
      "    accuracy                           0.75     80650\n",
      "   macro avg       0.70      0.70      0.67     80650\n",
      "weighted avg       0.85      0.75      0.77     80650\n",
      "\n",
      "Testing Confusion Matrix:\n",
      "[[  707  3051   227     9    66    29]\n",
      " [  516  9749   487    26   253   101]\n",
      " [  245   938  4592     1   278     8]\n",
      " [   72   387    91 18310     7     4]\n",
      " [  231  1055 11130     7 24532    45]\n",
      " [   52   619    59     1     3  2762]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Training Classification Report:\")\n",
    "print(classification_report(y_train, y_train_pred_xgb))\n",
    "\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_pred_xgb))\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Testing Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_xgb))\n",
    "\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pSKrfNda0CsF",
   "metadata": {
    "id": "pSKrfNda0CsF"
   },
   "source": [
    "\n",
    "\n",
    "*   We could see by implementing XGradientBoosting Classifier, there is improvement in performance metrics compared to gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XCfR3c9iRla3",
   "metadata": {
    "id": "XCfR3c9iRla3"
   },
   "source": [
    "#Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EGz4DNiHu0HN",
   "metadata": {
    "id": "EGz4DNiHu0HN"
   },
   "source": [
    "Since decision trees suffer from high variance quite often, the bagging method is consistently applied to trees. As we know bagging, that often considers homogeneous weak learners, learns them independently from each other in parallel and combines them following some kind of deterministic averaging process. Here we are applying bagging for our base models like decision trees and random forests individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pifysCYxUdzQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "id": "pifysCYxUdzQ",
    "outputId": "ec5936e4-7d02-488d-d7e6-36609f8a7d1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50,\n",
       "                  random_state=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50,\n",
       "                  random_state=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50,\n",
       "                  random_state=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing a bagged-tree classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=50, random_state=3)\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gmCGBcPpUnSY",
   "metadata": {
    "id": "gmCGBcPpUnSY"
   },
   "outputs": [],
   "source": [
    " # Finding the predictions of the bagged-tree classifier for train and test␣subsets\n",
    "train_y_pred = bag_clf.predict(X_train)\n",
    "test_y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wQnT52VrU3Yd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQnT52VrU3Yd",
    "outputId": "a8391e8b-9541-4be2-9574-002f821cb089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Trees Classifier Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.39      0.48     12264\n",
      "           1       0.75      0.94      0.83     33393\n",
      "           2       0.96      0.91      0.93     18184\n",
      "           3       1.00      0.99      1.00     40000\n",
      "           4       1.00      0.99      0.99     56000\n",
      "           5       0.99      0.82      0.90     10491\n",
      "\n",
      "    accuracy                           0.92    170332\n",
      "   macro avg       0.89      0.84      0.86    170332\n",
      "weighted avg       0.92      0.92      0.91    170332\n",
      " \n",
      "\n",
      "\n",
      "Bagged Trees Classifier Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.26      0.32      4089\n",
      "           1       0.64      0.82      0.72     11132\n",
      "           2       0.29      0.57      0.38      6062\n",
      "           3       1.00      0.97      0.98     18871\n",
      "           4       0.94      0.77      0.85     37000\n",
      "           5       0.89      0.79      0.84      3496\n",
      "\n",
      "    accuracy                           0.78     80650\n",
      "   macro avg       0.69      0.70      0.68     80650\n",
      "weighted avg       0.83      0.78      0.80     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score = metrics.accuracy_score(y_train, train_y_pred) # Compute train␣accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred) # Compute test␣accuracy\n",
    "train_report = classification_report(y_train, train_y_pred) # Generate␣classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred) # Generate␣classification report for test data\n",
    "print('Bagged Trees Classifier Train Classification Report: \\n\\n',train_report,'\\n\\n')\n",
    "print('Bagged Trees Classifier Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VDssiHGeWfn0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDssiHGeWfn0",
    "outputId": "7ca05443-e6b9-4b4a-b7f9-f11d798d4377"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Trees Classifier Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.35      0.44     12264\n",
      "           1       0.74      0.93      0.83     33393\n",
      "           2       0.94      0.90      0.92     18184\n",
      "           3       1.00      0.99      0.99     40000\n",
      "           4       0.99      0.98      0.99     56000\n",
      "           5       0.99      0.82      0.90     10491\n",
      "\n",
      "    accuracy                           0.91    170332\n",
      "   macro avg       0.87      0.83      0.84    170332\n",
      "weighted avg       0.91      0.91      0.90    170332\n",
      " \n",
      "\n",
      "\n",
      "Bagged Trees Classifier Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.17      0.25      4089\n",
      "           1       0.63      0.86      0.73     11132\n",
      "           2       0.29      0.58      0.39      6062\n",
      "           3       1.00      0.97      0.98     18871\n",
      "           4       0.94      0.78      0.85     37000\n",
      "           5       0.93      0.79      0.85      3496\n",
      "\n",
      "    accuracy                           0.79     80650\n",
      "   macro avg       0.70      0.69      0.67     80650\n",
      "weighted avg       0.84      0.79      0.80     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(base_estimator=RandomForestClassifier(),n_estimators=18, random_state=3)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "# Finding the predictions of the bagged-tree classifier for train and test␣subsets\n",
    "train_y_pred = bag_clf.predict(X_train)\n",
    "test_y_pred = bag_clf.predict(X_test)\n",
    "train_score = metrics.accuracy_score(y_train, train_y_pred) # Compute train␣accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred) # Compute test␣accuracy\n",
    "train_report = classification_report(y_train, train_y_pred) # Generate␣classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred) # Generate␣classification report for test data\n",
    "print('Bagged Trees Classifier Train Classification Report: \\n\\n',train_report,'\\n\\n')\n",
    "print('Bagged Trees Classifier Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nRtyqDj7x6hf",
   "metadata": {
    "id": "nRtyqDj7x6hf"
   },
   "source": [
    "The bagging method employs an averaging mechanism to reduce the variance and increase the accuracy of the test subset in a statistical learning method.\n",
    "When the weak learners are decision tress, the individual trees are constructed deep. Therefore,each individual tree has high variance, but low bias. Averaging the B trees reduces the variance. Bagging will mainly focus at getting an ensemble model with less variance than its components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ug-GoOAm0t2S",
   "metadata": {
    "id": "Ug-GoOAm0t2S"
   },
   "source": [
    "Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F8QLVhRKofiK",
   "metadata": {
    "id": "F8QLVhRKofiK"
   },
   "source": [
    "The idea of stacking is to learn several different weak learners and combine them by training a meta-model to output predictions based on the multiple predictions returned by these weak models. So, we need to define two things in order to build our stacking model: the L learners we want to fit and the meta-model that combines them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NauoHYc-ngtR",
   "metadata": {
    "id": "NauoHYc-ngtR"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define base models\n",
    "estimators = [\n",
    "    ('decision_tree', dt_classifier),\n",
    "    ('gradient_boosting', gb_classifier),\n",
    "    ('xtreme_gradient_boosting', xgb_classifier)\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Create StackingClassifier with base models and meta-model\n",
    "stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=meta_model)\n",
    "\n",
    "# Train StackingClassifier\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred_stack = stacking_classifier.predict(X_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred_stack = stacking_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U2Ixj6sIlxnv",
   "metadata": {
    "id": "U2Ixj6sIlxnv"
   },
   "outputs": [],
   "source": [
    "estimators = [('decision_tree', dt_classifier),\n",
    "              ('random_forest', clf),\n",
    "              ('gradient_boosting', gb_classifier)]\n",
    "stacking_classifier = StackingClassifier(estimators=estimators)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_train_pred_stack = stacking_classifier.predict(X_train)\n",
    "y_test_pred_stack = stacking_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WiR_yvzVmphK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiR_yvzVmphK",
    "outputId": "352eb4aa-30ed-4b01-e6b9-4b6625b26b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Stacking Classifier on Train Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.01      0.01     12264\n",
      "           1       0.67      0.99      0.80     33393\n",
      "           2       0.81      0.79      0.80     18184\n",
      "           3       1.00      0.98      0.99     40000\n",
      "           4       0.96      0.94      0.95     56000\n",
      "           5       0.96      0.79      0.86     10491\n",
      "\n",
      "    accuracy                           0.87    170332\n",
      "   macro avg       0.89      0.75      0.74    170332\n",
      "weighted avg       0.89      0.87      0.84    170332\n",
      "\n",
      "\n",
      "Classification Report for Stacking Classifier on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.02      4089\n",
      "           1       0.60      0.91      0.72     11132\n",
      "           2       0.26      0.69      0.38      6062\n",
      "           3       1.00      0.96      0.98     18871\n",
      "           4       0.96      0.69      0.80     37000\n",
      "           5       0.94      0.78      0.85      3496\n",
      "\n",
      "    accuracy                           0.75     80650\n",
      "   macro avg       0.68      0.67      0.63     80650\n",
      "weighted avg       0.83      0.75      0.76     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Stacking Classifier\n",
    "print(\"Classification Report for Stacking Classifier on Train Data:\\n\", classification_report(y_train, y_train_pred_stack))\n",
    "print(\"\\nClassification Report for Stacking Classifier on Test Data:\\n\", classification_report(y_test, y_test_pred_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tAYfC7uUNHLM",
   "metadata": {
    "id": "tAYfC7uUNHLM"
   },
   "source": [
    "* the Stacking Classifier demonstrates reasonably strong performance on both the training and test data, with relatively consistent performance across different classes. However, there is a slight drop in performance when transitioning from the training to the test data, suggesting some degree of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cQpUiAc1_G-M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQpUiAc1_G-M",
    "outputId": "70f70956-8364-4605-edd1-9ec22376a221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons==0.16.1\n",
      "  Downloading tensorflow_addons-0.16.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typeguard>=2.7 (from tensorflow-addons==0.16.1)\n",
      "  Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.11.0)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.16.1 typeguard-4.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons==0.16.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X8E5K2rz04f8",
   "metadata": {
    "id": "X8E5K2rz04f8"
   },
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mLQ3a1z95Ggr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLQ3a1z95Ggr",
    "outputId": "ef47b771-f8ce-4a92-b853-6af9a3f23520"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MGFPFSfF0_ia",
   "metadata": {
    "id": "MGFPFSfF0_ia"
   },
   "source": [
    "#Fully Connected Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UEHmRTD952eX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEHmRTD952eX",
    "outputId": "43d5be2f-a52a-4708-860e-ede46c7b6399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2654/2662 [============================>.] - ETA: 0s - loss: 1.3054 - accuracy: 0.5312 - categorical_accuracy: 7.0648e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.3051 - accuracy: 0.5313 - categorical_accuracy: 7.0451e-05 - val_loss: 1.2171 - val_accuracy: 0.6298 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2588 - accuracy: 0.5422 - categorical_accuracy: 4.1096e-05 - val_loss: 1.2068 - val_accuracy: 0.6302 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "2662/2662 [==============================] - 13s 5ms/step - loss: 1.2554 - accuracy: 0.5452 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2043 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2523 - accuracy: 0.5451 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2039 - val_accuracy: 0.6301 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2518 - accuracy: 0.5453 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2145 - val_accuracy: 0.6301 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2500 - accuracy: 0.5449 - categorical_accuracy: 0.0000e+00 - val_loss: 1.1986 - val_accuracy: 0.6303 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2481 - accuracy: 0.5454 - categorical_accuracy: 3.5225e-05 - val_loss: 1.1988 - val_accuracy: 0.6303 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2471 - accuracy: 0.5458 - categorical_accuracy: 1.1742e-05 - val_loss: 1.1961 - val_accuracy: 0.6302 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2458 - accuracy: 0.5457 - categorical_accuracy: 5.8709e-06 - val_loss: 1.1997 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2454 - accuracy: 0.5455 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2110 - val_accuracy: 0.6224 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2461 - accuracy: 0.5454 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2017 - val_accuracy: 0.6301 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2496 - accuracy: 0.5441 - categorical_accuracy: 0.0000e+00 - val_loss: 1.1875 - val_accuracy: 0.6302 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2451 - accuracy: 0.5467 - categorical_accuracy: 5.8709e-06 - val_loss: 1.1893 - val_accuracy: 0.6307 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "2662/2662 [==============================] - 8s 3ms/step - loss: 1.2444 - accuracy: 0.5478 - categorical_accuracy: 0.0000e+00 - val_loss: 1.1886 - val_accuracy: 0.6221 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2452 - accuracy: 0.5482 - categorical_accuracy: 2.3484e-05 - val_loss: 1.1903 - val_accuracy: 0.6303 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2441 - accuracy: 0.5477 - categorical_accuracy: 1.1742e-05 - val_loss: 1.1959 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "2662/2662 [==============================] - 8s 3ms/step - loss: 1.2464 - accuracy: 0.5481 - categorical_accuracy: 6.4580e-05 - val_loss: 1.2015 - val_accuracy: 0.6305 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2427 - accuracy: 0.5490 - categorical_accuracy: 5.8709e-06 - val_loss: 1.2107 - val_accuracy: 0.6155 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "2662/2662 [==============================] - 8s 3ms/step - loss: 1.2402 - accuracy: 0.5493 - categorical_accuracy: 1.1742e-05 - val_loss: 1.1895 - val_accuracy: 0.6307 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2403 - accuracy: 0.5489 - categorical_accuracy: 5.8709e-06 - val_loss: 1.1996 - val_accuracy: 0.6155 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2419 - accuracy: 0.5496 - categorical_accuracy: 5.8709e-06 - val_loss: 1.2004 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2394 - accuracy: 0.5500 - categorical_accuracy: 3.5225e-05 - val_loss: 1.2067 - val_accuracy: 0.6150 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2412 - accuracy: 0.5498 - categorical_accuracy: 5.8709e-06 - val_loss: 1.1922 - val_accuracy: 0.6231 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "2662/2662 [==============================] - 12s 5ms/step - loss: 1.2393 - accuracy: 0.5505 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2038 - val_accuracy: 0.6099 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2435 - accuracy: 0.5486 - categorical_accuracy: 5.8709e-06 - val_loss: 1.1980 - val_accuracy: 0.6232 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2436 - accuracy: 0.5498 - categorical_accuracy: 1.7613e-05 - val_loss: 1.2015 - val_accuracy: 0.6206 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2523 - accuracy: 0.5448 - categorical_accuracy: 0.0000e+00 - val_loss: 1.1928 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2498 - accuracy: 0.5462 - categorical_accuracy: 1.7613e-05 - val_loss: 1.1998 - val_accuracy: 0.6099 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2433 - accuracy: 0.5490 - categorical_accuracy: 5.2838e-05 - val_loss: 1.1917 - val_accuracy: 0.6232 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2398 - accuracy: 0.5498 - categorical_accuracy: 4.1096e-05 - val_loss: 1.1887 - val_accuracy: 0.6304 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2392 - accuracy: 0.5504 - categorical_accuracy: 3.5225e-05 - val_loss: 1.1924 - val_accuracy: 0.6225 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2406 - accuracy: 0.5500 - categorical_accuracy: 4.6967e-05 - val_loss: 1.1955 - val_accuracy: 0.6152 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2420 - accuracy: 0.5504 - categorical_accuracy: 4.1096e-05 - val_loss: 1.1978 - val_accuracy: 0.6153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2409 - accuracy: 0.5508 - categorical_accuracy: 5.2838e-05 - val_loss: 1.1927 - val_accuracy: 0.6305 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "2662/2662 [==============================] - 8s 3ms/step - loss: 1.2416 - accuracy: 0.5507 - categorical_accuracy: 4.1096e-05 - val_loss: 1.1844 - val_accuracy: 0.6233 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2424 - accuracy: 0.5496 - categorical_accuracy: 1.1742e-05 - val_loss: 1.1941 - val_accuracy: 0.6153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2482 - accuracy: 0.5462 - categorical_accuracy: 0.0000e+00 - val_loss: 1.1951 - val_accuracy: 0.6151 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2418 - accuracy: 0.5487 - categorical_accuracy: 2.3484e-05 - val_loss: 1.2060 - val_accuracy: 0.6152 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2384 - accuracy: 0.5503 - categorical_accuracy: 1.0568e-04 - val_loss: 1.1895 - val_accuracy: 0.6236 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2404 - accuracy: 0.5495 - categorical_accuracy: 1.1742e-04 - val_loss: 1.1898 - val_accuracy: 0.6156 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2375 - accuracy: 0.5507 - categorical_accuracy: 7.0451e-05 - val_loss: 1.1902 - val_accuracy: 0.6236 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2439 - accuracy: 0.5478 - categorical_accuracy: 3.5225e-05 - val_loss: 1.1864 - val_accuracy: 0.6153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2430 - accuracy: 0.5471 - categorical_accuracy: 3.5225e-05 - val_loss: 1.1993 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "2662/2662 [==============================] - 8s 3ms/step - loss: 1.2473 - accuracy: 0.5467 - categorical_accuracy: 9.3934e-05 - val_loss: 1.1924 - val_accuracy: 0.6153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2490 - accuracy: 0.5453 - categorical_accuracy: 2.9354e-05 - val_loss: 1.1935 - val_accuracy: 0.6306 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2445 - accuracy: 0.5469 - categorical_accuracy: 1.3503e-04 - val_loss: 1.1953 - val_accuracy: 0.6099 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2419 - accuracy: 0.5491 - categorical_accuracy: 1.4090e-04 - val_loss: 1.1940 - val_accuracy: 0.6099 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2399 - accuracy: 0.5500 - categorical_accuracy: 1.3503e-04 - val_loss: 1.1973 - val_accuracy: 0.6099 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2433 - accuracy: 0.5482 - categorical_accuracy: 4.1096e-05 - val_loss: 1.1909 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2454 - accuracy: 0.5484 - categorical_accuracy: 1.2916e-04 - val_loss: 1.1950 - val_accuracy: 0.6152 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2441 - accuracy: 0.5481 - categorical_accuracy: 2.9354e-05 - val_loss: 1.1934 - val_accuracy: 0.6099 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2442 - accuracy: 0.5488 - categorical_accuracy: 7.0451e-05 - val_loss: 1.1824 - val_accuracy: 0.6152 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "2662/2662 [==============================] - 8s 3ms/step - loss: 1.2443 - accuracy: 0.5487 - categorical_accuracy: 5.8709e-05 - val_loss: 1.1986 - val_accuracy: 0.6099 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2477 - accuracy: 0.5477 - categorical_accuracy: 5.2838e-05 - val_loss: 1.1983 - val_accuracy: 0.6211 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2541 - accuracy: 0.5448 - categorical_accuracy: 2.3484e-05 - val_loss: 1.1951 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2496 - accuracy: 0.5458 - categorical_accuracy: 5.2838e-05 - val_loss: 1.2004 - val_accuracy: 0.6152 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2518 - accuracy: 0.5455 - categorical_accuracy: 5.8709e-05 - val_loss: 1.1985 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2511 - accuracy: 0.5448 - categorical_accuracy: 2.3484e-05 - val_loss: 1.1895 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2522 - accuracy: 0.5452 - categorical_accuracy: 5.2838e-05 - val_loss: 1.1895 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2441 - accuracy: 0.5491 - categorical_accuracy: 3.5225e-05 - val_loss: 1.1914 - val_accuracy: 0.6153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2439 - accuracy: 0.5486 - categorical_accuracy: 7.6322e-05 - val_loss: 1.1998 - val_accuracy: 0.6102 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2428 - accuracy: 0.5490 - categorical_accuracy: 4.1096e-05 - val_loss: 1.1957 - val_accuracy: 0.6235 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2429 - accuracy: 0.5493 - categorical_accuracy: 4.6967e-05 - val_loss: 1.1944 - val_accuracy: 0.6102 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2420 - accuracy: 0.5497 - categorical_accuracy: 7.0451e-05 - val_loss: 1.1999 - val_accuracy: 0.6102 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2431 - accuracy: 0.5485 - categorical_accuracy: 7.6322e-05 - val_loss: 1.1918 - val_accuracy: 0.6156 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2435 - accuracy: 0.5486 - categorical_accuracy: 6.4580e-05 - val_loss: 1.1885 - val_accuracy: 0.6153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2434 - accuracy: 0.5489 - categorical_accuracy: 2.7593e-04 - val_loss: 1.2039 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2431 - accuracy: 0.5496 - categorical_accuracy: 9.9805e-05 - val_loss: 1.1945 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2434 - accuracy: 0.5495 - categorical_accuracy: 1.1742e-04 - val_loss: 1.2008 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2424 - accuracy: 0.5492 - categorical_accuracy: 1.7613e-05 - val_loss: 1.1939 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2435 - accuracy: 0.5497 - categorical_accuracy: 4.1096e-05 - val_loss: 1.1887 - val_accuracy: 0.6156 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2468 - accuracy: 0.5468 - categorical_accuracy: 8.2192e-05 - val_loss: 1.2042 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2430 - accuracy: 0.5477 - categorical_accuracy: 2.9354e-05 - val_loss: 1.1935 - val_accuracy: 0.6153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2425 - accuracy: 0.5486 - categorical_accuracy: 5.2838e-05 - val_loss: 1.1950 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2445 - accuracy: 0.5487 - categorical_accuracy: 8.8063e-05 - val_loss: 1.1857 - val_accuracy: 0.6233 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2427 - accuracy: 0.5496 - categorical_accuracy: 4.6967e-05 - val_loss: 1.1920 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2430 - accuracy: 0.5494 - categorical_accuracy: 4.6967e-05 - val_loss: 1.1944 - val_accuracy: 0.6101 - val_categorical_accuracy: 1.7359e-04\n",
      "Epoch 78/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2429 - accuracy: 0.5493 - categorical_accuracy: 1.2329e-04 - val_loss: 1.1912 - val_accuracy: 0.6154 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2418 - accuracy: 0.5502 - categorical_accuracy: 1.1155e-04 - val_loss: 1.1881 - val_accuracy: 0.6235 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2435 - accuracy: 0.5497 - categorical_accuracy: 8.8063e-05 - val_loss: 1.1905 - val_accuracy: 0.6154 - val_categorical_accuracy: 6.1996e-05\n",
      "Epoch 81/100\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2410 - accuracy: 0.5499 - categorical_accuracy: 1.1155e-04 - val_loss: 1.2007 - val_accuracy: 0.6102 - val_categorical_accuracy: 2.2319e-04\n",
      "Epoch 82/100\n",
      "2662/2662 [==============================] - 8s 3ms/step - loss: 1.2419 - accuracy: 0.5498 - categorical_accuracy: 8.8063e-05 - val_loss: 1.1876 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2427 - accuracy: 0.5496 - categorical_accuracy: 7.0451e-05 - val_loss: 1.1921 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2427 - accuracy: 0.5493 - categorical_accuracy: 7.0451e-05 - val_loss: 1.1963 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2426 - accuracy: 0.5496 - categorical_accuracy: 7.0451e-05 - val_loss: 1.2013 - val_accuracy: 0.6101 - val_categorical_accuracy: 8.6795e-05\n",
      "Epoch 86/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2419 - accuracy: 0.5501 - categorical_accuracy: 1.0568e-04 - val_loss: 1.1990 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "2662/2662 [==============================] - 12s 4ms/step - loss: 1.2430 - accuracy: 0.5491 - categorical_accuracy: 1.8787e-04 - val_loss: 1.1861 - val_accuracy: 0.6102 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2453 - accuracy: 0.5486 - categorical_accuracy: 1.4090e-04 - val_loss: 1.1995 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2419 - accuracy: 0.5497 - categorical_accuracy: 8.8063e-05 - val_loss: 1.1916 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2413 - accuracy: 0.5496 - categorical_accuracy: 9.3934e-05 - val_loss: 1.1937 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2413 - accuracy: 0.5497 - categorical_accuracy: 1.6438e-04 - val_loss: 1.2002 - val_accuracy: 0.6104 - val_categorical_accuracy: 2.6038e-04\n",
      "Epoch 92/100\n",
      "2662/2662 [==============================] - 8s 3ms/step - loss: 1.2468 - accuracy: 0.5487 - categorical_accuracy: 1.1155e-04 - val_loss: 1.2004 - val_accuracy: 0.6102 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2449 - accuracy: 0.5486 - categorical_accuracy: 1.0568e-04 - val_loss: 1.2010 - val_accuracy: 0.6101 - val_categorical_accuracy: 3.3478e-04\n",
      "Epoch 94/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2454 - accuracy: 0.5487 - categorical_accuracy: 2.1135e-04 - val_loss: 1.1945 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2449 - accuracy: 0.5491 - categorical_accuracy: 1.2329e-04 - val_loss: 1.2002 - val_accuracy: 0.6105 - val_categorical_accuracy: 2.2319e-04\n",
      "Epoch 96/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2428 - accuracy: 0.5496 - categorical_accuracy: 1.2329e-04 - val_loss: 1.1961 - val_accuracy: 0.6104 - val_categorical_accuracy: 1.2399e-04\n",
      "Epoch 97/100\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2420 - accuracy: 0.5504 - categorical_accuracy: 9.3934e-05 - val_loss: 1.1986 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2421 - accuracy: 0.5499 - categorical_accuracy: 1.2916e-04 - val_loss: 1.1980 - val_accuracy: 0.6101 - val_categorical_accuracy: 3.0998e-04\n",
      "Epoch 99/100\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2419 - accuracy: 0.5495 - categorical_accuracy: 1.1155e-04 - val_loss: 1.1956 - val_accuracy: 0.6102 - val_categorical_accuracy: 3.3478e-04\n",
      "Epoch 100/100\n",
      "2662/2662 [==============================] - 12s 5ms/step - loss: 1.2447 - accuracy: 0.5485 - categorical_accuracy: 1.2329e-04 - val_loss: 1.2054 - val_accuracy: 0.6101 - val_categorical_accuracy: 1.7359e-04\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model_FNN = models.Sequential()\n",
    "model_FNN.add(layers.Dense(64, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "model_FNN.add(layers.Dropout(0.2))  # Add dropout regularization\n",
    "model_FNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_FNN.add(layers.Dropout(0.2))  # Add dropout regularization\n",
    "model_FNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_FNN.add(layers.Dropout(0.2))  # Add dropout regularization\n",
    "model_FNN.add(layers.Dense(6, activation='softmax'))  # Change num_classes to the number of classes in your target variable\n",
    "\n",
    "# Compile the model\n",
    "model_FNN.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', 'categorical_accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_FNN.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ji8S6AC6yUnA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ji8S6AC6yUnA",
    "outputId": "d11efa02-1da5-4bdf-feeb-7b14bda805d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5323/5323 [==============================] - 8s 1ms/step\n",
      "[4 4 1 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Predict FNN on the train set results\n",
    "\n",
    "y_pred_train = model_FNN.predict(X_train)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eYjkRnDSx0la",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYjkRnDSx0la",
    "outputId": "26a34f8f-c452-4491-9085-72e42c2e3f5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2521/2521 [==============================] - 3s 1ms/step\n",
      "[3 3 3 ... 4 4 3]\n"
     ]
    }
   ],
   "source": [
    "# Predict FNN on the test set results\n",
    "\n",
    "y_pred_test = model_FNN.predict(X_test)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jMDEtSs4zRW8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMDEtSs4zRW8",
    "outputId": "850554c9-dcb6-4431-82c1-3d84581e442c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12264\n",
      "           1       0.40      0.26      0.31     33393\n",
      "           2       0.00      0.00      0.00     18184\n",
      "           3       0.53      0.99      0.69     40000\n",
      "           4       0.65      0.86      0.74     56000\n",
      "           5       0.00      0.00      0.00     10491\n",
      "\n",
      "    accuracy                           0.56    170332\n",
      "   macro avg       0.26      0.35      0.29    170332\n",
      "weighted avg       0.42      0.56      0.47    170332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report for train data\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_imkspSy4f93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_imkspSy4f93",
    "outputId": "7be6514a-1c7f-4714-ee21-564c0f181cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4089\n",
      "           1       0.27      0.28      0.28     11132\n",
      "           2       0.00      0.00      0.00      6062\n",
      "           3       0.57      0.97      0.72     18871\n",
      "           4       0.73      0.73      0.73     37000\n",
      "           5       0.00      0.00      0.00      3496\n",
      "\n",
      "    accuracy                           0.60     80650\n",
      "   macro avg       0.26      0.33      0.29     80650\n",
      "weighted avg       0.51      0.60      0.54     80650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report for test data\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OqeaMJECwJq1",
   "metadata": {
    "id": "OqeaMJECwJq1"
   },
   "source": [
    "Overall, the model gives a consistent but relatively low performance across both training and test data with 56% and 60% accuracy scores. The model struggles to effectively distinguish between certain classes, particularly minority classes 0, 2, and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-h9hY0AbHlGE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "-h9hY0AbHlGE",
    "outputId": "7e35b365-834e-4981-946b-c99a5e5161d5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A6KbVPw4-DVR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6KbVPw4-DVR",
    "outputId": "42c6ce67-357e-42d1-95cf-232cf389c1d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2652/2662 [============================>.] - ETA: 0s - loss: 1.3062 - accuracy: 0.5293 - categorical_accuracy: 2.7691e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2662/2662 [==============================] - 13s 5ms/step - loss: 1.3060 - accuracy: 0.5293 - categorical_accuracy: 2.7593e-04 - val_loss: 1.2361 - val_accuracy: 0.6289 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2555 - accuracy: 0.5435 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2100 - val_accuracy: 0.6189 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2435 - accuracy: 0.5481 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2105 - val_accuracy: 0.6125 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2411 - accuracy: 0.5517 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2047 - val_accuracy: 0.6129 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2374 - accuracy: 0.5551 - categorical_accuracy: 1.7613e-05 - val_loss: 1.1974 - val_accuracy: 0.6169 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2342 - accuracy: 0.5558 - categorical_accuracy: 5.8709e-05 - val_loss: 1.2076 - val_accuracy: 0.6149 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2329 - accuracy: 0.5565 - categorical_accuracy: 7.6322e-05 - val_loss: 1.1957 - val_accuracy: 0.6170 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2288 - accuracy: 0.5565 - categorical_accuracy: 1.1742e-04 - val_loss: 1.2034 - val_accuracy: 0.6022 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2311 - accuracy: 0.5568 - categorical_accuracy: 8.8063e-05 - val_loss: 1.1990 - val_accuracy: 0.6024 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2288 - accuracy: 0.5572 - categorical_accuracy: 3.0529e-04 - val_loss: 1.1975 - val_accuracy: 0.6065 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2288 - accuracy: 0.5575 - categorical_accuracy: 8.8063e-05 - val_loss: 1.1960 - val_accuracy: 0.6065 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2253 - accuracy: 0.5585 - categorical_accuracy: 1.1155e-04 - val_loss: 1.1899 - val_accuracy: 0.6084 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2292 - accuracy: 0.5571 - categorical_accuracy: 9.9805e-05 - val_loss: 1.1949 - val_accuracy: 0.6066 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2264 - accuracy: 0.5586 - categorical_accuracy: 7.6322e-05 - val_loss: 1.1976 - val_accuracy: 0.6066 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2275 - accuracy: 0.5580 - categorical_accuracy: 3.5225e-05 - val_loss: 1.1848 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2256 - accuracy: 0.5595 - categorical_accuracy: 3.5225e-05 - val_loss: 1.1956 - val_accuracy: 0.6021 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2231 - accuracy: 0.5597 - categorical_accuracy: 4.6967e-05 - val_loss: 1.2015 - val_accuracy: 0.6020 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "2662/2662 [==============================] - 12s 5ms/step - loss: 1.2271 - accuracy: 0.5578 - categorical_accuracy: 5.8709e-05 - val_loss: 1.1959 - val_accuracy: 0.6007 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2290 - accuracy: 0.5574 - categorical_accuracy: 1.7613e-05 - val_loss: 1.2071 - val_accuracy: 0.6041 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2304 - accuracy: 0.5574 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2013 - val_accuracy: 0.6021 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "2662/2662 [==============================] - 12s 5ms/step - loss: 1.2299 - accuracy: 0.5576 - categorical_accuracy: 2.3484e-05 - val_loss: 1.1909 - val_accuracy: 0.6022 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "2662/2662 [==============================] - 12s 5ms/step - loss: 1.2283 - accuracy: 0.5586 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2067 - val_accuracy: 0.6021 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "2662/2662 [==============================] - 12s 5ms/step - loss: 1.2269 - accuracy: 0.5595 - categorical_accuracy: 2.5832e-04 - val_loss: 1.1879 - val_accuracy: 0.6066 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "2662/2662 [==============================] - 12s 4ms/step - loss: 1.2407 - accuracy: 0.5522 - categorical_accuracy: 8.8063e-05 - val_loss: 1.2057 - val_accuracy: 0.5984 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "2662/2662 [==============================] - 13s 5ms/step - loss: 1.2367 - accuracy: 0.5532 - categorical_accuracy: 0.0000e+00 - val_loss: 1.1982 - val_accuracy: 0.5984 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "2662/2662 [==============================] - 13s 5ms/step - loss: 1.2346 - accuracy: 0.5538 - categorical_accuracy: 5.8709e-06 - val_loss: 1.1988 - val_accuracy: 0.5986 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2338 - accuracy: 0.5555 - categorical_accuracy: 0.0000e+00 - val_loss: 1.1930 - val_accuracy: 0.6028 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2367 - accuracy: 0.5554 - categorical_accuracy: 2.9354e-05 - val_loss: 1.2021 - val_accuracy: 0.6011 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2301 - accuracy: 0.5575 - categorical_accuracy: 5.8709e-05 - val_loss: 1.2126 - val_accuracy: 0.6006 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2325 - accuracy: 0.5553 - categorical_accuracy: 5.8709e-05 - val_loss: 1.1982 - val_accuracy: 0.5985 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "2662/2662 [==============================] - 9s 4ms/step - loss: 1.2306 - accuracy: 0.5565 - categorical_accuracy: 1.4090e-04 - val_loss: 1.2078 - val_accuracy: 0.6000 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2302 - accuracy: 0.5565 - categorical_accuracy: 2.1135e-04 - val_loss: 1.1976 - val_accuracy: 0.6005 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2338 - accuracy: 0.5548 - categorical_accuracy: 1.1742e-04 - val_loss: 1.2035 - val_accuracy: 0.6006 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2430 - accuracy: 0.5510 - categorical_accuracy: 1.7613e-05 - val_loss: 1.2077 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2387 - accuracy: 0.5532 - categorical_accuracy: 2.9354e-05 - val_loss: 1.1954 - val_accuracy: 0.6007 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "2662/2662 [==============================] - 13s 5ms/step - loss: 1.2469 - accuracy: 0.5502 - categorical_accuracy: 3.5225e-05 - val_loss: 1.2084 - val_accuracy: 0.6009 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2451 - accuracy: 0.5520 - categorical_accuracy: 2.3484e-05 - val_loss: 1.2091 - val_accuracy: 0.5943 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2435 - accuracy: 0.5511 - categorical_accuracy: 1.7613e-05 - val_loss: 1.2119 - val_accuracy: 0.5964 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2481 - accuracy: 0.5492 - categorical_accuracy: 5.8709e-06 - val_loss: 1.1929 - val_accuracy: 0.6021 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2390 - accuracy: 0.5542 - categorical_accuracy: 4.6967e-05 - val_loss: 1.1902 - val_accuracy: 0.6018 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2387 - accuracy: 0.5524 - categorical_accuracy: 1.7613e-04 - val_loss: 1.2081 - val_accuracy: 0.5996 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2482 - accuracy: 0.5480 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2155 - val_accuracy: 0.5982 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2435 - accuracy: 0.5486 - categorical_accuracy: 0.0000e+00 - val_loss: 1.2048 - val_accuracy: 0.5996 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2419 - accuracy: 0.5508 - categorical_accuracy: 1.1742e-05 - val_loss: 1.1999 - val_accuracy: 0.6003 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2481 - accuracy: 0.5483 - categorical_accuracy: 3.5225e-05 - val_loss: 1.2002 - val_accuracy: 0.5990 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2441 - accuracy: 0.5515 - categorical_accuracy: 1.2916e-04 - val_loss: 1.2146 - val_accuracy: 0.6006 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "2662/2662 [==============================] - 11s 4ms/step - loss: 1.2427 - accuracy: 0.5509 - categorical_accuracy: 1.1155e-04 - val_loss: 1.2098 - val_accuracy: 0.5969 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2399 - accuracy: 0.5520 - categorical_accuracy: 1.2329e-04 - val_loss: 1.1907 - val_accuracy: 0.6065 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "2662/2662 [==============================] - 9s 3ms/step - loss: 1.2349 - accuracy: 0.5549 - categorical_accuracy: 1.1155e-04 - val_loss: 1.2062 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "2662/2662 [==============================] - 10s 4ms/step - loss: 1.2413 - accuracy: 0.5514 - categorical_accuracy: 1.7613e-05 - val_loss: 1.2045 - val_accuracy: 0.5960 - val_categorical_accuracy: 0.0000e+00\n",
      "5323/5323 [==============================] - 9s 2ms/step\n",
      "2521/2521 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12264\n",
      "           1       0.38      0.22      0.28     33393\n",
      "           2       0.00      0.00      0.00     18184\n",
      "           3       0.51      0.99      0.67     40000\n",
      "           4       0.65      0.86      0.74     56000\n",
      "           5       0.00      0.00      0.00     10491\n",
      "\n",
      "    accuracy                           0.56    170332\n",
      "   macro avg       0.26      0.34      0.28    170332\n",
      "weighted avg       0.41      0.56      0.46    170332\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4089\n",
      "           1       0.27      0.27      0.27     11132\n",
      "           2       0.00      0.00      0.00      6062\n",
      "           3       0.55      0.97      0.70     18871\n",
      "           4       0.74      0.72      0.73     37000\n",
      "           5       0.00      0.00      0.00      3496\n",
      "\n",
      "    accuracy                           0.60     80650\n",
      "   macro avg       0.26      0.33      0.28     80650\n",
      "weighted avg       0.50      0.60      0.54     80650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model_FNN = models.Sequential()\n",
    "model_FNN.add(layers.Dense(64, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "model_FNN.add(layers.Dropout(0.2))  # Add dropout regularization\n",
    "model_FNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_FNN.add(layers.Dropout(0.2))  # Add dropout regularization\n",
    "model_FNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_FNN.add(layers.Dropout(0.2))  # Add dropout regularization\n",
    "model_FNN.add(layers.Dense(6, activation='softmax'))  # Change num_classes to the number of classes in your target variable\n",
    "\n",
    "# Compile the model\n",
    "model_FNN.compile(optimizer=tf.keras.optimizers.AdamW(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', 'categorical_accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_FNN.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "y_pred_train = model_FNN.predict(X_train)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "\n",
    "y_pred_test = model_FNN.predict(X_test)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "#classification report for train data\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "#classification report for test data\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vUzze_qEwVED",
   "metadata": {
    "id": "vUzze_qEwVED"
   },
   "source": [
    "As you can see, after applying adamw optimizer also we could see there is no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cP6vAF1awOp2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cP6vAF1awOp2",
    "outputId": "b5802309-4973-4ad7-e355-3b719473365d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5323/5323 [==============================] - 35s 6ms/step - loss: 0.7011 - accuracy: 0.7174 - categorical_accuracy: 0.0179 - val_loss: 0.6603 - val_accuracy: 0.6889 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5323/5323 [==============================] - 38s 7ms/step - loss: 0.5322 - accuracy: 0.7823 - categorical_accuracy: 0.0109 - val_loss: 0.6166 - val_accuracy: 0.7036 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "5323/5323 [==============================] - 33s 6ms/step - loss: 0.4973 - accuracy: 0.7951 - categorical_accuracy: 0.0081 - val_loss: 0.5673 - val_accuracy: 0.7276 - val_categorical_accuracy: 0.0068\n",
      "Epoch 4/10\n",
      "5323/5323 [==============================] - 33s 6ms/step - loss: 0.4778 - accuracy: 0.8005 - categorical_accuracy: 0.0071 - val_loss: 0.5708 - val_accuracy: 0.7224 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "5323/5323 [==============================] - 33s 6ms/step - loss: 0.4634 - accuracy: 0.8053 - categorical_accuracy: 0.0056 - val_loss: 0.5710 - val_accuracy: 0.7093 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "5323/5323 [==============================] - 38s 7ms/step - loss: 0.4525 - accuracy: 0.8080 - categorical_accuracy: 0.0055 - val_loss: 0.5604 - val_accuracy: 0.7402 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "5323/5323 [==============================] - 34s 6ms/step - loss: 0.4454 - accuracy: 0.8102 - categorical_accuracy: 0.0040 - val_loss: 0.5175 - val_accuracy: 0.7618 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "5323/5323 [==============================] - 33s 6ms/step - loss: 0.4379 - accuracy: 0.8125 - categorical_accuracy: 0.0026 - val_loss: 0.5462 - val_accuracy: 0.7486 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "5323/5323 [==============================] - 33s 6ms/step - loss: 0.4342 - accuracy: 0.8142 - categorical_accuracy: 0.0026 - val_loss: 0.5469 - val_accuracy: 0.7046 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "5323/5323 [==============================] - 37s 7ms/step - loss: 0.4298 - accuracy: 0.8149 - categorical_accuracy: 0.0032 - val_loss: 0.4894 - val_accuracy: 0.7465 - val_categorical_accuracy: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7cfd1476e920>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model_CNN = models.Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model_CNN.add(layers.Conv1D(64, 3, activation='sigmoid', input_shape=(X_train.shape[1], 1)))\n",
    "model_CNN.add(layers.MaxPooling1D(2))\n",
    "model_CNN.add(layers.Conv1D(64, 3, activation='sigmoid'))\n",
    "model_CNN.add(layers.MaxPooling1D(2))\n",
    "\n",
    "# Flatten the output before passing it to the dense layers\n",
    "model_CNN.add(layers.Flatten())\n",
    "\n",
    "# Add dense layers with dropout regularization\n",
    "model_CNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_CNN.add(layers.Dropout(0.2))\n",
    "model_CNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_CNN.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model_CNN.add(layers.Dense(6, activation='softmax'))  # Change num_classes to the number of classes in your target variable\n",
    "\n",
    "# Compile the model\n",
    "model_CNN.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', 'categorical_accuracy'])\n",
    "# Convert DataFrame to numpy array\n",
    "X_train_array = X_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "\n",
    "# Reshape the input data to include a channel dimension\n",
    "X_train_reshaped = X_train_array.reshape(X_train_array.shape[0], X_train_array.shape[1], 1)\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], X_test_array.shape[1], 1)\n",
    "\n",
    "# Train the model\n",
    "history=model_CNN.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L5xqFvbi4yar",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5xqFvbi4yar",
    "outputId": "9b99a38b-31e0-4725-e5a0-f906336b8f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5323/5323 [==============================] - 13s 2ms/step\n",
      "[1 1 1 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Predict CNN on the train set results\n",
    "\n",
    "y_pred_train = model_CNN.predict(X_train_reshaped)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cy_BkLE_5nUr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cy_BkLE_5nUr",
    "outputId": "e98de0fb-aba6-438d-ddaf-7a0e031f2ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2521/2521 [==============================] - 5s 2ms/step\n",
      "[2 2 2 ... 4 4 2]\n"
     ]
    }
   ],
   "source": [
    "# Predict CNN on the test set results\n",
    "\n",
    "y_pred_test = model_CNN.predict(X_test_reshaped)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dS6WyGI95ztP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dS6WyGI95ztP",
    "outputId": "068cf2a3-942d-4bc5-a8c5-ca06e5150af9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.00      0.01     12264\n",
      "           1       0.64      0.91      0.75     33393\n",
      "           2       0.61      0.73      0.67     18184\n",
      "           3       1.00      0.98      0.99     40000\n",
      "           4       0.94      0.88      0.91     56000\n",
      "           5       0.85      0.78      0.81     10491\n",
      "\n",
      "    accuracy                           0.82    170332\n",
      "   macro avg       0.74      0.71      0.69    170332\n",
      "weighted avg       0.82      0.82      0.80    170332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report for train data\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xVLTuuIj57oR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVLTuuIj57oR",
    "outputId": "70f6d311-0320-4678-e90a-a8cf29a4ecb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.00      0.01      4089\n",
      "           1       0.58      0.90      0.71     11132\n",
      "           2       0.25      0.62      0.35      6062\n",
      "           3       1.00      0.95      0.97     18871\n",
      "           4       0.96      0.69      0.80     37000\n",
      "           5       0.83      0.82      0.83      3496\n",
      "\n",
      "    accuracy                           0.75     80650\n",
      "   macro avg       0.63      0.67      0.61     80650\n",
      "weighted avg       0.82      0.75      0.76     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report for test data\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14JB9WcwxZ98",
   "metadata": {
    "id": "14JB9WcwxZ98"
   },
   "source": [
    "For CNN, we could see it's treating minority classes 2, and 5 better comparitively to FNN. But there is no significant improvement for 0 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KJpYAaBqVwwL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "KJpYAaBqVwwL",
    "outputId": "ff3b8dfa-f78a-420c-cc79-e8c23ef37b52"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9a67585db075>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpyplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    227\u001b[0m             f\"module {cls.__module__!r} has no attribute {name!r}\")\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dNaBgqLBhfCT",
   "metadata": {
    "id": "dNaBgqLBhfCT"
   },
   "source": [
    "* Overall, the model shows good performance in the majority of classes but struggles with class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Au38wGF1DBHL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Au38wGF1DBHL",
    "outputId": "b484a2e8-bb2b-4ffa-bb47-8708acefc8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5323/5323 [==============================] - 50s 9ms/step - loss: 0.7040 - accuracy: 0.7157 - categorical_accuracy: 0.0111 - val_loss: 0.7042 - val_accuracy: 0.6576 - val_categorical_accuracy: 0.0014\n",
      "Epoch 2/50\n",
      "5323/5323 [==============================] - 47s 9ms/step - loss: 0.5311 - accuracy: 0.7824 - categorical_accuracy: 0.0109 - val_loss: 0.5918 - val_accuracy: 0.7252 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4940 - accuracy: 0.7955 - categorical_accuracy: 0.0075 - val_loss: 0.5823 - val_accuracy: 0.7204 - val_categorical_accuracy: 0.0100\n",
      "Epoch 4/50\n",
      "5323/5323 [==============================] - 43s 8ms/step - loss: 0.4780 - accuracy: 0.8012 - categorical_accuracy: 0.0069 - val_loss: 0.5466 - val_accuracy: 0.7557 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "5323/5323 [==============================] - 40s 8ms/step - loss: 0.4670 - accuracy: 0.8049 - categorical_accuracy: 0.0032 - val_loss: 0.5530 - val_accuracy: 0.7337 - val_categorical_accuracy: 1.2399e-05\n",
      "Epoch 6/50\n",
      "5323/5323 [==============================] - 42s 8ms/step - loss: 0.4580 - accuracy: 0.8067 - categorical_accuracy: 0.0027 - val_loss: 0.5371 - val_accuracy: 0.7296 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4507 - accuracy: 0.8088 - categorical_accuracy: 0.0020 - val_loss: 0.6168 - val_accuracy: 0.6960 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4460 - accuracy: 0.8104 - categorical_accuracy: 0.0014 - val_loss: 0.5282 - val_accuracy: 0.7457 - val_categorical_accuracy: 1.2399e-05\n",
      "Epoch 9/50\n",
      "5323/5323 [==============================] - 44s 8ms/step - loss: 0.4409 - accuracy: 0.8124 - categorical_accuracy: 0.0016 - val_loss: 0.5260 - val_accuracy: 0.7300 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4362 - accuracy: 0.8137 - categorical_accuracy: 0.0012 - val_loss: 0.5431 - val_accuracy: 0.7482 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "5323/5323 [==============================] - 48s 9ms/step - loss: 0.4332 - accuracy: 0.8143 - categorical_accuracy: 0.0015 - val_loss: 0.5408 - val_accuracy: 0.7481 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "5323/5323 [==============================] - 47s 9ms/step - loss: 0.4300 - accuracy: 0.8156 - categorical_accuracy: 0.0022 - val_loss: 0.5127 - val_accuracy: 0.7436 - val_categorical_accuracy: 6.6956e-04\n",
      "Epoch 13/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4285 - accuracy: 0.8174 - categorical_accuracy: 0.0022 - val_loss: 0.5037 - val_accuracy: 0.7521 - val_categorical_accuracy: 1.2399e-04\n",
      "Epoch 14/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4268 - accuracy: 0.8167 - categorical_accuracy: 0.0023 - val_loss: 0.5158 - val_accuracy: 0.7683 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "5323/5323 [==============================] - 44s 8ms/step - loss: 0.4246 - accuracy: 0.8180 - categorical_accuracy: 0.0021 - val_loss: 0.5063 - val_accuracy: 0.7696 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "5323/5323 [==============================] - 42s 8ms/step - loss: 0.4234 - accuracy: 0.8180 - categorical_accuracy: 0.0017 - val_loss: 0.4700 - val_accuracy: 0.8052 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4216 - accuracy: 0.8186 - categorical_accuracy: 0.0027 - val_loss: 0.5159 - val_accuracy: 0.7462 - val_categorical_accuracy: 7.0676e-04\n",
      "Epoch 18/50\n",
      "5323/5323 [==============================] - 45s 9ms/step - loss: 0.4189 - accuracy: 0.8191 - categorical_accuracy: 0.0024 - val_loss: 0.5029 - val_accuracy: 0.7440 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4180 - accuracy: 0.8196 - categorical_accuracy: 0.0028 - val_loss: 0.4953 - val_accuracy: 0.7549 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "5323/5323 [==============================] - 43s 8ms/step - loss: 0.4171 - accuracy: 0.8203 - categorical_accuracy: 0.0017 - val_loss: 0.5030 - val_accuracy: 0.7801 - val_categorical_accuracy: 1.8599e-04\n",
      "Epoch 21/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4161 - accuracy: 0.8203 - categorical_accuracy: 0.0025 - val_loss: 0.4725 - val_accuracy: 0.7870 - val_categorical_accuracy: 3.8438e-04\n",
      "Epoch 22/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4144 - accuracy: 0.8211 - categorical_accuracy: 0.0017 - val_loss: 0.4998 - val_accuracy: 0.7746 - val_categorical_accuracy: 4.7117e-04\n",
      "Epoch 23/50\n",
      "5323/5323 [==============================] - 42s 8ms/step - loss: 0.4146 - accuracy: 0.8214 - categorical_accuracy: 0.0031 - val_loss: 0.5074 - val_accuracy: 0.7497 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4114 - accuracy: 0.8226 - categorical_accuracy: 0.0035 - val_loss: 0.4769 - val_accuracy: 0.7986 - val_categorical_accuracy: 2.7278e-04\n",
      "Epoch 25/50\n",
      "5323/5323 [==============================] - 42s 8ms/step - loss: 0.4113 - accuracy: 0.8219 - categorical_accuracy: 0.0016 - val_loss: 0.5344 - val_accuracy: 0.7475 - val_categorical_accuracy: 4.9597e-04\n",
      "Epoch 26/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4115 - accuracy: 0.8220 - categorical_accuracy: 0.0024 - val_loss: 0.4867 - val_accuracy: 0.7837 - val_categorical_accuracy: 3.8438e-04\n",
      "Epoch 27/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4096 - accuracy: 0.8226 - categorical_accuracy: 0.0026 - val_loss: 0.5087 - val_accuracy: 0.7423 - val_categorical_accuracy: 1.3639e-04\n",
      "Epoch 28/50\n",
      "5323/5323 [==============================] - 48s 9ms/step - loss: 0.4104 - accuracy: 0.8228 - categorical_accuracy: 0.0027 - val_loss: 0.4899 - val_accuracy: 0.7600 - val_categorical_accuracy: 5.3317e-04\n",
      "Epoch 29/50\n",
      "5323/5323 [==============================] - 43s 8ms/step - loss: 0.4086 - accuracy: 0.8234 - categorical_accuracy: 0.0035 - val_loss: 0.5071 - val_accuracy: 0.7639 - val_categorical_accuracy: 0.0011\n",
      "Epoch 30/50\n",
      "5323/5323 [==============================] - 46s 9ms/step - loss: 0.4071 - accuracy: 0.8234 - categorical_accuracy: 0.0029 - val_loss: 0.4771 - val_accuracy: 0.7662 - val_categorical_accuracy: 6.5716e-04\n",
      "Epoch 31/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4076 - accuracy: 0.8236 - categorical_accuracy: 0.0029 - val_loss: 0.4803 - val_accuracy: 0.7739 - val_categorical_accuracy: 1.8599e-04\n",
      "Epoch 32/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4064 - accuracy: 0.8241 - categorical_accuracy: 0.0023 - val_loss: 0.5127 - val_accuracy: 0.7617 - val_categorical_accuracy: 4.7117e-04\n",
      "Epoch 33/50\n",
      "5323/5323 [==============================] - 49s 9ms/step - loss: 0.4065 - accuracy: 0.8243 - categorical_accuracy: 0.0028 - val_loss: 0.5086 - val_accuracy: 0.7587 - val_categorical_accuracy: 1.4879e-04\n",
      "Epoch 34/50\n",
      "5323/5323 [==============================] - 48s 9ms/step - loss: 0.4064 - accuracy: 0.8246 - categorical_accuracy: 0.0030 - val_loss: 0.4870 - val_accuracy: 0.7655 - val_categorical_accuracy: 5.7037e-04\n",
      "Epoch 35/50\n",
      "5323/5323 [==============================] - 44s 8ms/step - loss: 0.4058 - accuracy: 0.8242 - categorical_accuracy: 0.0037 - val_loss: 0.5053 - val_accuracy: 0.7601 - val_categorical_accuracy: 0.0022\n",
      "Epoch 36/50\n",
      "5323/5323 [==============================] - 45s 9ms/step - loss: 0.4042 - accuracy: 0.8245 - categorical_accuracy: 0.0042 - val_loss: 0.4892 - val_accuracy: 0.7536 - val_categorical_accuracy: 3.8438e-04\n",
      "Epoch 37/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4052 - accuracy: 0.8244 - categorical_accuracy: 0.0031 - val_loss: 0.4937 - val_accuracy: 0.7739 - val_categorical_accuracy: 0.0040\n",
      "Epoch 38/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4040 - accuracy: 0.8253 - categorical_accuracy: 0.0044 - val_loss: 0.4846 - val_accuracy: 0.7730 - val_categorical_accuracy: 4.5877e-04\n",
      "Epoch 39/50\n",
      "5323/5323 [==============================] - 42s 8ms/step - loss: 0.4030 - accuracy: 0.8257 - categorical_accuracy: 0.0046 - val_loss: 0.5002 - val_accuracy: 0.7626 - val_categorical_accuracy: 0.0020\n",
      "Epoch 40/50\n",
      "5323/5323 [==============================] - 41s 8ms/step - loss: 0.4040 - accuracy: 0.8260 - categorical_accuracy: 0.0043 - val_loss: 0.4819 - val_accuracy: 0.7875 - val_categorical_accuracy: 0.0014\n",
      "Epoch 41/50\n",
      "5323/5323 [==============================] - 44s 8ms/step - loss: 0.4020 - accuracy: 0.8260 - categorical_accuracy: 0.0045 - val_loss: 0.4904 - val_accuracy: 0.7630 - val_categorical_accuracy: 9.2994e-04\n",
      "Epoch 42/50\n",
      "5323/5323 [==============================] - 42s 8ms/step - loss: 0.4042 - accuracy: 0.8254 - categorical_accuracy: 0.0046 - val_loss: 0.4894 - val_accuracy: 0.7581 - val_categorical_accuracy: 0.0030\n",
      "Epoch 43/50\n",
      "5323/5323 [==============================] - 46s 9ms/step - loss: 0.4015 - accuracy: 0.8260 - categorical_accuracy: 0.0046 - val_loss: 0.4658 - val_accuracy: 0.7860 - val_categorical_accuracy: 9.6714e-04\n",
      "Epoch 44/50\n",
      "5323/5323 [==============================] - 46s 9ms/step - loss: 0.4020 - accuracy: 0.8252 - categorical_accuracy: 0.0060 - val_loss: 0.4593 - val_accuracy: 0.8008 - val_categorical_accuracy: 0.0034\n",
      "Epoch 45/50\n",
      "5323/5323 [==============================] - 43s 8ms/step - loss: 0.4010 - accuracy: 0.8261 - categorical_accuracy: 0.0050 - val_loss: 0.4703 - val_accuracy: 0.7662 - val_categorical_accuracy: 0.0027\n",
      "Epoch 46/50\n",
      "5323/5323 [==============================] - 43s 8ms/step - loss: 0.4004 - accuracy: 0.8263 - categorical_accuracy: 0.0065 - val_loss: 0.4741 - val_accuracy: 0.7774 - val_categorical_accuracy: 0.0013\n",
      "Epoch 47/50\n",
      "5323/5323 [==============================] - 47s 9ms/step - loss: 0.4004 - accuracy: 0.8266 - categorical_accuracy: 0.0063 - val_loss: 0.4820 - val_accuracy: 0.7919 - val_categorical_accuracy: 0.0026\n",
      "Epoch 48/50\n",
      "5323/5323 [==============================] - 50s 9ms/step - loss: 0.4003 - accuracy: 0.8267 - categorical_accuracy: 0.0063 - val_loss: 0.5030 - val_accuracy: 0.7582 - val_categorical_accuracy: 0.0021\n",
      "Epoch 49/50\n",
      "5323/5323 [==============================] - 48s 9ms/step - loss: 0.3994 - accuracy: 0.8271 - categorical_accuracy: 0.0048 - val_loss: 0.4871 - val_accuracy: 0.7708 - val_categorical_accuracy: 0.0046\n",
      "Epoch 50/50\n",
      "5323/5323 [==============================] - 45s 8ms/step - loss: 0.4005 - accuracy: 0.8269 - categorical_accuracy: 0.0066 - val_loss: 0.4719 - val_accuracy: 0.7790 - val_categorical_accuracy: 0.0026\n",
      "5323/5323 [==============================] - 14s 3ms/step\n",
      "2521/2521 [==============================] - 8s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.02      0.04     12264\n",
      "           1       0.64      0.94      0.76     33393\n",
      "           2       0.69      0.67      0.68     18184\n",
      "           3       1.00      0.98      0.99     40000\n",
      "           4       0.92      0.91      0.92     56000\n",
      "           5       0.87      0.77      0.82     10491\n",
      "\n",
      "    accuracy                           0.83    170332\n",
      "   macro avg       0.81      0.72      0.70    170332\n",
      "weighted avg       0.84      0.83      0.81    170332\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.03      0.05      4089\n",
      "           1       0.57      0.93      0.71     11132\n",
      "           2       0.29      0.52      0.37      6062\n",
      "           3       1.00      0.96      0.98     18871\n",
      "           4       0.94      0.76      0.84     37000\n",
      "           5       0.86      0.81      0.84      3496\n",
      "\n",
      "    accuracy                           0.78     80650\n",
      "   macro avg       0.70      0.67      0.63     80650\n",
      "weighted avg       0.83      0.78      0.78     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model_CNN = models.Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model_CNN.add(layers.Conv1D(64, 3, activation='sigmoid', input_shape=(X_train.shape[1], 1)))\n",
    "model_CNN.add(layers.MaxPooling1D(2))\n",
    "model_CNN.add(layers.Conv1D(64, 3, activation='sigmoid'))\n",
    "model_CNN.add(layers.MaxPooling1D(2))\n",
    "\n",
    "# Flatten the output before passing it to the dense layers\n",
    "model_CNN.add(layers.Flatten())\n",
    "\n",
    "# Add dense layers with dropout regularization\n",
    "model_CNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_CNN.add(layers.Dropout(0.2))\n",
    "model_CNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_CNN.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model_CNN.add(layers.Dense(6, activation='softmax'))  # Change num_classes to the number of classes in your target variable\n",
    "\n",
    "# Compile the model\n",
    "model_CNN.compile(optimizer=tf.keras.optimizers.AdamW(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', 'categorical_accuracy'])\n",
    "# Convert DataFrame to numpy array\n",
    "X_train_array = X_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "\n",
    "# Reshape the input data to include a channel dimension\n",
    "X_train_reshaped = X_train_array.reshape(X_train_array.shape[0], X_train_array.shape[1], 1)\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], X_test_array.shape[1], 1)\n",
    "\n",
    "# Train the model\n",
    "history=model_CNN.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "y_pred_train = model_CNN.predict(X_train_reshaped)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "\n",
    "y_pred_test = model_CNN.predict(X_test_reshaped)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "#classification report for train data\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "#classification report for test data\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oFfTsA4e08tD",
   "metadata": {
    "id": "oFfTsA4e08tD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "CIMGNzgv0eVj",
   "metadata": {
    "id": "CIMGNzgv0eVj"
   },
   "source": [
    "For CNN, after using Adamw optimizer we could see for minority class 0 there is improvement in precision. But there is no improvement in recall and f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dvJt-00W1Pb7",
   "metadata": {
    "id": "dvJt-00W1Pb7"
   },
   "source": [
    "#Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DL7JLjligC86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DL7JLjligC86",
    "outputId": "c9030018-0e76-4ceb-b912-00336b4d6c37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5323/5323 [==============================] - 87s 16ms/step - loss: 0.9507 - accuracy: 0.6351 - categorical_accuracy: 0.0028 - val_loss: 0.8899 - val_accuracy: 0.6633 - val_categorical_accuracy: 0.0134\n",
      "Epoch 2/10\n",
      "5323/5323 [==============================] - 86s 16ms/step - loss: 0.6399 - accuracy: 0.7484 - categorical_accuracy: 0.0169 - val_loss: 0.6834 - val_accuracy: 0.6882 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "5323/5323 [==============================] - 95s 18ms/step - loss: 0.5815 - accuracy: 0.7657 - categorical_accuracy: 0.0072 - val_loss: 0.6352 - val_accuracy: 0.6904 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "5323/5323 [==============================] - 94s 18ms/step - loss: 0.5514 - accuracy: 0.7730 - categorical_accuracy: 0.0019 - val_loss: 0.7323 - val_accuracy: 0.6574 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "5323/5323 [==============================] - 85s 16ms/step - loss: 0.5344 - accuracy: 0.7799 - categorical_accuracy: 0.0014 - val_loss: 0.5860 - val_accuracy: 0.7058 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "5323/5323 [==============================] - 85s 16ms/step - loss: 0.5194 - accuracy: 0.7860 - categorical_accuracy: 0.0013 - val_loss: 0.6127 - val_accuracy: 0.7088 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "5323/5323 [==============================] - 85s 16ms/step - loss: 0.5017 - accuracy: 0.7929 - categorical_accuracy: 0.0028 - val_loss: 0.5674 - val_accuracy: 0.7317 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "5323/5323 [==============================] - 86s 16ms/step - loss: 0.4891 - accuracy: 0.7974 - categorical_accuracy: 0.0044 - val_loss: 0.5653 - val_accuracy: 0.7124 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "5323/5323 [==============================] - 87s 16ms/step - loss: 0.4776 - accuracy: 0.8004 - categorical_accuracy: 0.0028 - val_loss: 0.5512 - val_accuracy: 0.7241 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "5323/5323 [==============================] - 95s 18ms/step - loss: 0.4734 - accuracy: 0.8019 - categorical_accuracy: 0.0016 - val_loss: 0.5617 - val_accuracy: 0.7183 - val_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7cfd2958fa30>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model_RNN = models.Sequential()\n",
    "\n",
    "# Add a SimpleRNN layer\n",
    "model_RNN.add(layers.SimpleRNN(64, activation='sigmoid', input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model_RNN.add(layers.SimpleRNN(64, activation='sigmoid'))\n",
    "\n",
    "# Add dense layers with dropout regularization\n",
    "model_RNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_RNN.add(layers.Dropout(0.2))\n",
    "model_RNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_RNN.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model_RNN.add(layers.Dense(6, activation='softmax'))  # Change num_classes to the number of classes in your target variable\n",
    "\n",
    "# Compile the model\n",
    "model_RNN.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', 'categorical_accuracy'])\n",
    "\n",
    "# Convert DataFrame to numpy array\n",
    "X_train_array = X_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "\n",
    "# Reshape the input data to include a time step dimension\n",
    "X_train_reshaped = X_train_array.reshape(X_train_array.shape[0], X_train_array.shape[1], 1)\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], X_test_array.shape[1], 1)\n",
    "\n",
    "# Train the model\n",
    "history=model_RNN.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jBNLT60c9gVM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBNLT60c9gVM",
    "outputId": "855ef54c-0215-441b-ecfb-ab9bdfdeba9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5323/5323 [==============================] - 27s 5ms/step\n",
      "[1 1 1 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Predict RNN on the train set results\n",
    "\n",
    "y_pred_train = model_RNN.predict(X_train_reshaped)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6lnsErLm-fJd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lnsErLm-fJd",
    "outputId": "2dc5a326-f0ef-46f1-9f7b-75b398fe20bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2521/2521 [==============================] - 12s 5ms/step\n",
      "[2 2 2 ... 4 4 2]\n"
     ]
    }
   ],
   "source": [
    "# Predict RNN on the test set results\n",
    "\n",
    "y_pred_test = model_RNN.predict(X_test_reshaped)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G4D8zOn5_UjN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4D8zOn5_UjN",
    "outputId": "146a8f11-1307-474a-8881-7d65a2e29b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12264\n",
      "           1       0.60      0.95      0.74     33393\n",
      "           2       0.57      0.75      0.65     18184\n",
      "           3       1.00      0.98      0.99     40000\n",
      "           4       0.98      0.82      0.89     56000\n",
      "           5       0.92      0.65      0.76     10491\n",
      "\n",
      "    accuracy                           0.81    170332\n",
      "   macro avg       0.68      0.69      0.67    170332\n",
      "weighted avg       0.79      0.81      0.79    170332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report for train data\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CoAyKfsG_bhJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CoAyKfsG_bhJ",
    "outputId": "4c8b2868-4665-4366-ad12-a14707d0c769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4089\n",
      "           1       0.51      0.93      0.66     11132\n",
      "           2       0.25      0.66      0.36      6062\n",
      "           3       1.00      0.96      0.98     18871\n",
      "           4       0.98      0.62      0.76     37000\n",
      "           5       0.89      0.71      0.79      3496\n",
      "\n",
      "    accuracy                           0.72     80650\n",
      "   macro avg       0.61      0.65      0.59     80650\n",
      "weighted avg       0.81      0.72      0.73     80650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report for test data\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AR-mxqhfV3Pu",
   "metadata": {
    "id": "AR-mxqhfV3Pu"
   },
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yvVMm8gcn-UV",
   "metadata": {
    "id": "yvVMm8gcn-UV"
   },
   "source": [
    "* RNN model performs reasonably well on the majority of classes but struggles significantly with class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OM_976obLpDT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OM_976obLpDT",
    "outputId": "052c22a1-45f6-46ee-9adc-5bf4ecc42930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5323/5323 [==============================] - 119s 21ms/step - loss: 0.9640 - accuracy: 0.6304 - categorical_accuracy: 0.0043 - val_loss: 1.0024 - val_accuracy: 0.5949 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5323/5323 [==============================] - 113s 21ms/step - loss: 0.6424 - accuracy: 0.7504 - categorical_accuracy: 0.0078 - val_loss: 0.8450 - val_accuracy: 0.6365 - val_categorical_accuracy: 7.8115e-04\n",
      "Epoch 3/10\n",
      "5323/5323 [==============================] - 102s 19ms/step - loss: 0.5854 - accuracy: 0.7672 - categorical_accuracy: 0.0094 - val_loss: 0.7451 - val_accuracy: 0.6641 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "5323/5323 [==============================] - 111s 21ms/step - loss: 0.5608 - accuracy: 0.7759 - categorical_accuracy: 0.0024 - val_loss: 0.7330 - val_accuracy: 0.6594 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "5323/5323 [==============================] - 125s 24ms/step - loss: 0.5429 - accuracy: 0.7824 - categorical_accuracy: 0.0015 - val_loss: 0.6749 - val_accuracy: 0.6847 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "5323/5323 [==============================] - 126s 24ms/step - loss: 0.5223 - accuracy: 0.7899 - categorical_accuracy: 0.0011 - val_loss: 0.6905 - val_accuracy: 0.6713 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "5323/5323 [==============================] - 111s 21ms/step - loss: 0.5099 - accuracy: 0.7930 - categorical_accuracy: 9.7457e-04 - val_loss: 0.6452 - val_accuracy: 0.7026 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "5323/5323 [==============================] - 113s 21ms/step - loss: 0.4968 - accuracy: 0.7966 - categorical_accuracy: 0.0013 - val_loss: 0.5911 - val_accuracy: 0.7196 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "5323/5323 [==============================] - 105s 20ms/step - loss: 0.4849 - accuracy: 0.7993 - categorical_accuracy: 4.5793e-04 - val_loss: 0.5968 - val_accuracy: 0.7087 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "5323/5323 [==============================] - 109s 20ms/step - loss: 0.4782 - accuracy: 0.8014 - categorical_accuracy: 9.0999e-04 - val_loss: 0.5721 - val_accuracy: 0.7369 - val_categorical_accuracy: 0.0000e+00\n",
      "5323/5323 [==============================] - 35s 7ms/step\n",
      "2521/2521 [==============================] - 17s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12264\n",
      "           1       0.63      0.92      0.75     33393\n",
      "           2       0.57      0.72      0.63     18184\n",
      "           3       0.99      0.98      0.98     40000\n",
      "           4       0.95      0.85      0.90     56000\n",
      "           5       0.81      0.70      0.75     10491\n",
      "\n",
      "    accuracy                           0.81    170332\n",
      "   macro avg       0.66      0.69      0.67    170332\n",
      "weighted avg       0.78      0.81      0.79    170332\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4089\n",
      "           1       0.57      0.87      0.69     11132\n",
      "           2       0.25      0.61      0.35      6062\n",
      "           3       0.98      0.95      0.96     18871\n",
      "           4       0.95      0.69      0.80     37000\n",
      "           5       0.73      0.74      0.74      3496\n",
      "\n",
      "    accuracy                           0.74     80650\n",
      "   macro avg       0.58      0.64      0.59     80650\n",
      "weighted avg       0.80      0.74      0.75     80650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model_RNN = models.Sequential()\n",
    "\n",
    "# Add a SimpleRNN layer\n",
    "model_RNN.add(layers.SimpleRNN(64, activation='sigmoid', input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model_RNN.add(layers.SimpleRNN(64, activation='sigmoid'))\n",
    "\n",
    "# Add dense layers with dropout regularization\n",
    "model_RNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_RNN.add(layers.Dropout(0.2))\n",
    "model_RNN.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_RNN.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model_RNN.add(layers.Dense(6, activation='softmax'))  # Change num_classes to the number of classes in your target variable\n",
    "\n",
    "# Compile the model\n",
    "model_RNN.compile(optimizer=tf.keras.optimizers.AdamW(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', 'categorical_accuracy'])\n",
    "\n",
    "# Convert DataFrame to numpy array\n",
    "X_train_array = X_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "\n",
    "# Reshape the input data to include a time step dimension\n",
    "X_train_reshaped = X_train_array.reshape(X_train_array.shape[0], X_train_array.shape[1], 1)\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], X_test_array.shape[1], 1)\n",
    "\n",
    "# Train the model\n",
    "history=model_RNN.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Predict RNN on the train set results\n",
    "y_pred_train = model_RNN.predict(X_train_reshaped)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "\n",
    "# Predict RNN on the test set results\n",
    "y_pred_test = model_RNN.predict(X_test_reshaped)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "#classification report for train data\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "#classification report for test data\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2XZVBt6z17BG",
   "metadata": {
    "id": "2XZVBt6z17BG"
   },
   "source": [
    "There is no impact on class 0 even after for applying adamw optimizer for RNN."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
